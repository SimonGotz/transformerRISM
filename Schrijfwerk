Todo schrijven thesis:

- Abstract updaten

INTRODUCTION

- Other representations veranderen?
- hard triplets introduceren

Relevant Works

- Incipit voorbeeld veranderen
- Stuk over pretrainen erbij?
- Hard triplets

METHODS

3.1 Data:
- Data exploratie toevoegen:
	- Tune family distribution
		* Misschien wat grotere classes analyseren
	- Max, min, median, mode toevoegen aan melody length dist
	- Distributie van jaren plotten
- Voorbeeld veranderen van tunefamily(tunefamily 5855_0)

3.2 Architecture:
Positional encoding
		* inzichtelijk maken middels een grafiek

3.4 Evaluation:
- Misschien een stuk over visualisation

3.5 Experimental Setup:

4 Results:

4.1 Tuning:
	- Invloed individuele parameters weergeven

4.2 Model Performance:
	- Attention heads visualiseren

Conclusie:
- Subkopjes maken

Discussie:
- Subkopjes maken

Miscelanious:
- Footnotes rechttrekken
- Proeflezen
- Latex warnings wegwerken

CHANGELOG (24-02-2025)
- Introductie RQ's aangepast
- Sectie 3.1:
	- uitgebreid met train, test en validation split 
	- Subsectie data exploratie toegevoegd:
		* Feature selectie
		* Statistieken over de datas
		* Afbeelding Class size distributie toegevoegd
- Sectie 3.2 Model Architecture helemaal veranderd:
	- Flowchart gemaakt voor transformer architectuur
	- Flowchart model gemaakt voor encoder layer
	- High level overview gegeven van transformer architectuur
	- Input embedding uitgelegd
	- Attention figuren toegevoegd
	- Attention sectie uitgebreid
	- Normalisation en feed forward uitleg uitgebreid
	- Pooling sectie toegevoegd
	- Stukje Positional encoding toegevoegd
- Sectie 3.3 implementation:
	- Data flow model een update gegeven.
	- Tekst update gegeven
- Sectie 3.4 evaluation:
	- Silhouete coefficient toegevoegd als evaluatie metric
- Sectie 3.5 experimental setup:
	* Hyperparameter tuning in meer detail uitgelegd
	* Experimenten logischer opgedeeld
	* Experiment toegevoegd: model performance
	* Statistische testen geintroduceerd
- Sectie 4.1 Tuning Results:
	* Eerste results toegevoegd van hyperparameter training
	

Vragen:
- RQ: RQ1 opdelen in twee subvragen?
- Evaluatie:
	* Hoe pairwise comparisons doen?
	* Hier ook vertellen wat ik ga plotten?
	* Metrics die nog interessant kunnen zijn?
	* Hoe vergelijk ik met baseline papers?
- Hoevaak een subsectie extended met nog een subsectie?
- Moet er nog een hypothese bij?
- Is Comparison with baseline models een experiment? Of is dat evaluatie? -> bij experiment 2
	Is het misschien: Model performance -> welke van de 8 combinaties is het best?
	Of is het 1 experiment dat alle modellen getrained moeten worden -> waaruit de evaluatie antwoord geeft op de vragen
- Wat te doen als model te snel lokaal optimum vind? kijken na 10 epochs en anders herstarten?
- Het model lijkt sowieso extreem snel te convergeren, wat in tegenstrijd is met de natuur van transformers


Feedback Peter:
- Datapoint:
	* transcripted -> transcribed
	* Terminologie universeel krijg; zelfde spelling
- 18,500 points zijn goed -> 12,344 is na cleaning
- Eerder refereren naar table 1
- Tegenwoordige tijd schrijven
- 3.1.2 explicieter maken en duidelijker
- Data split -> experimental setup
- Feature parsing -> hoort niet bij de data
- Feature parsing -> paragraaf per onderdeel met duidelijk voorbeeld en concrete bewerkingen
- Motivatie achter pooling beter uitleggen
- Implementation -> hoeft er niet in
- Hyperparameters uitleggen
- Fases uitleggen -> train, validatie, test
- Hard triplets -> triplet mining toevoegen
- Experiment 2 beter uitleggen dat elk model eigen configuratie heeft
- Statistiek later eventueel 
- Results ook terugkoppelen naar RQ 