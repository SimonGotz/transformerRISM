CONFIGURATION: 
Training time: 729 
lr: 0.001
wd: 0.1
d_model: 256
n_heads: 16
n_layers: 4
d_ff: 128
batch_size: 1024
dropout: 0.12080876392188705
margin: 0.5634362228878893
epsilon: 1e-05
Train losses 
0.7017183184623719
0.6844255208969117
0.6321406364440918
0.5414952039718628
0.5617000341415406
0.5481571674346923
0.5603907346725464
0.5450486898422241
0.5266342282295227
0.5245116055011749
0.5396923899650574
0.5351656794548034
0.5378509044647217
0.5381858706474304
0.5363640785217285
0.536695921421051
0.5317408919334412
0.5236810684204102
0.5419428586959839
0.5389530301094055
0.4821669816970825
0.504536259174347
0.47048702239990237
0.46553693413734437
0.4685978293418884
0.5060902535915375
0.48457199335098267
0.44842434525489805
0.4749895453453064
0.45773611068725584
Val losses 
0.31860271096229553
0.3081992268562317
0.26921194791793823
0.27608031034469604
0.27296364307403564
0.3011625111103058
0.2838149666786194
0.2983955442905426
0.29324302077293396
0.3206321597099304
0.3222891390323639
0.285611093044281
0.3116382360458374
0.2939426898956299
0.3283410966396332
0.314380019903183
0.31685107946395874
0.3296818733215332
0.32119137048721313
0.3021214008331299
0.3342228829860687
0.36343005299568176
0.39285996556282043
0.29487118124961853
0.3184800446033478
0.33050644397735596
0.3033212125301361
0.3435384929180145
0.35737109184265137
0.3071865141391754
