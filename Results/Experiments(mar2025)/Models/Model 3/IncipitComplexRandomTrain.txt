CONFIGURATION: 
Training time: 624 
lr: 0.001
wd: 0.0005
d_model: 128
n_heads: 8
n_layers: 4
d_ff: 128
batch_size: 32
dropout: 0.13044757965657483
margin: 0.7295125606056299
epsilon: 1e-08
Train losses 
0.45609617701598576
0.31317462844508037
0.26841384657791684
0.24015699871948787
0.2286120656132698
0.21420656400067464
0.2012730859858649
0.19274841385228295
0.17549299444471086
0.17210821781839644
0.16361394992896489
0.15830598132950918
0.14330841464655739
0.1440159389802388
0.15283456248896463
0.1354236240046365
0.13486851330314364
0.1303920213665281
0.1341147151163646
0.12472092509269714
Val losses 
0.32453829050064087
0.22474798560142517
0.20640499889850616
0.21799959242343903
0.2047015130519867
0.18407531082630157
0.169759601354599
0.13882848620414734
0.15219953656196594
0.13156373798847198
0.1388792246580124
0.12553851306438446
0.13808970153331757
0.12218081951141357
0.1304512321949005
0.08222654461860657
0.13097122311592102
0.11524319648742676
0.11923214793205261
0.1044505164027214
