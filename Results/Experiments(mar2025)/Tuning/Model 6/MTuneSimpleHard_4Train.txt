CONFIGURATION: 
Training time: 78 
lr: 1e-05
wd: 0.05
d_model: 32
n_heads: 4
n_layers: 1
d_ff: 128
batch_size: 512
dropout: 0.05779972971230707
margin: 0.17549500441646174
epsilon: 1e-06
Train losses 
0.4087103188037872
0.40521771013736724
0.4067443132400513
0.4051303952932358
0.4272037923336029
0.41206568777561187
0.3878221452236176
0.3945120245218277
0.41543619632720946
0.40123133063316346
0.39042911529541013
0.37548792362213135
0.3905474364757538
0.3826418250799179
0.3909811109304428
Val losses 
0.23247869312763214
0.23301321268081665
0.23773039877414703
0.2519921064376831
0.24648956954479218
0.2355656623840332
0.23291581869125366
0.23438416421413422
0.24169084429740906
0.224421426653862
0.2536524832248688
0.22292430698871613
0.24278156459331512
0.24333231151103973
0.2444576472043991
