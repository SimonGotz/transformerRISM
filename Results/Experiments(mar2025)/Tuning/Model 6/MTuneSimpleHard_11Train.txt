CONFIGURATION: 
Training time: 498 
lr: 1e-05
wd: 0.1
d_model: 64
n_heads: 16
n_layers: 4
d_ff: 128
batch_size: 512
dropout: 0.011537733536007622
margin: 0.47572397041648207
epsilon: 0.0001
Train losses 
0.6052380383014679
0.5760589838027954
0.591090589761734
0.5822137951850891
0.6039182782173157
0.5683685064315795
0.5976783514022828
0.59816854596138
0.6053657710552216
0.5906637847423554
Val losses 
0.33380326628685
0.36423420906066895
0.3625587224960327
0.33996954560279846
0.34433627128601074
0.3299199640750885
0.3553851246833801
0.34846124053001404
0.367035835981369
0.33935895562171936
