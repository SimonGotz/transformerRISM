CONFIGURATION: 
Training time: 93 
lr: 2e-05
wd: 0.1
d_model: 16
n_heads: 2
n_layers: 2
d_ff: 512
batch_size: 1024
dropout: 0.23879566085847925
margin: 0.32296479795926497
epsilon: 0.0001
Train losses 
0.5447144091129303
0.5086695849895477
0.508947080373764
0.5412578344345093
0.5375652551651001
0.5177793860435486
0.5069474518299103
0.5014778852462769
0.5150185227394104
0.5032438278198242
Val losses 
0.20608477294445038
0.21578478813171387
0.20958325266838074
0.20351746678352356
0.2115534096956253
0.20146650075912476
0.20670004189014435
0.21819032728672028
0.20257531106472015
0.20356319844722748
