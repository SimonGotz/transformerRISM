CONFIGURATION: 
Training time: 94 
lr: 0.002
wd: 0.1
d_model: 16
n_heads: 8
n_layers: 4
d_ff: 2048
batch_size: 1024
dropout: 0.11362504327347434
margin: 0.2674997215857968
epsilon: 1e-08
Train losses 
0.3813123762607574
0.30647077560424807
0.30559809803962706
0.31315075159072875
0.31732422709465025
0.31788449883461
0.2966992437839508
0.2903537452220917
0.2835179388523102
0.280282586812973
Val losses 
0.1521252691745758
0.21129797399044037
0.23468418419361115
0.2328299582004547
0.2311875820159912
0.23320044577121735
0.23345479369163513
0.23233771324157715
0.23541177809238434
0.2257353514432907
