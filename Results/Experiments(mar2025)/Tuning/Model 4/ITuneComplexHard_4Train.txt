CONFIGURATION: 
Training time: 138 
lr: 0.0001
wd: 0.0005
d_model: 16
n_heads: 4
n_layers: 3
d_ff: 2048
batch_size: 1024
dropout: 0.09871473838111139
margin: 0.29346177545578733
epsilon: 1e-05
Train losses 
0.5588495373725891
0.49973665475845336
0.4361466109752655
0.3845665752887726
0.3478245437145233
0.3360736846923828
0.32368984818458557
0.30948222875595094
0.32134788632392886
0.3066970944404602
0.3138879954814911
0.3181640625
0.31092641949653627
0.3084567904472351
0.3105871737003326
Val losses 
0.24287931621074677
0.21904052793979645
0.19899417459964752
0.1663701832294464
0.16312465071678162
0.16952146589756012
0.17209523916244507
0.16722631454467773
0.17037168145179749
0.16904541850090027
0.1702403575181961
0.16644959151744843
0.17115049064159393
0.17170126736164093
0.1747104823589325
