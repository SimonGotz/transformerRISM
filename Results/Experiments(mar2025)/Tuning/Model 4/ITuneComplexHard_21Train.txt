CONFIGURATION: 
Training time: 88 
lr: 0.0001
wd: 0.05
d_model: 32
n_heads: 4
n_layers: 1
d_ff: 128
batch_size: 1024
dropout: 0.210269187302412
margin: 0.3142666307101813
epsilon: 1e-05
Train losses 
0.558442759513855
0.5633825778961181
0.5475788533687591
0.5713463425636292
0.5499423742294312
0.532439363002777
0.5784406423568725
0.5779405474662781
0.5627883315086365
0.5443146109580994
0.5359951138496399
0.534338504076004
0.5214577317237854
0.5601956486701966
0.5373359382152557
Val losses 
0.2064915895462036
0.23954255878925323
0.21590518951416016
0.20604951679706573
0.2190900295972824
0.21030274033546448
0.21589092910289764
0.21775127947330475
0.2184682935476303
0.22235983610153198
0.21739870309829712
0.2110678106546402
0.20984648168087006
0.22231833636760712
0.20754209160804749
