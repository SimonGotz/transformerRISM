CONFIGURATION: 
Training time: 72 
lr: 0.002
wd: 0.1
d_model: 128
n_heads: 4
n_layers: 1
d_ff: 256
batch_size: 1024
dropout: 0.09453486437657915
margin: 0.34085000744905347
epsilon: 0.0001
Train losses 
0.5298812747001648
0.5198333203792572
0.4677422285079956
0.3959205150604248
0.3890398383140564
0.3767943739891052
0.35993845462799073
0.36205882430076597
0.35787259936332705
0.35211425423622134
Val losses 
0.2476309984922409
0.2731056809425354
0.2270912379026413
0.22000336647033691
0.21374675631523132
0.19665955007076263
0.2016395479440689
0.20328067243099213
0.213226780295372
0.20550625026226044
