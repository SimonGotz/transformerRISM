CONFIGURATION: 
Training time: 131 
lr: 2e-05
wd: 0.0001
d_model: 512
n_heads: 8
n_layers: 1
d_ff: 512
batch_size: 256
dropout: 0.10017865394742959
margin: 0.3068282939208786
epsilon: 1e-07
Train losses 
0.31947141601925805
0.3122048165116991
0.3279403462296441
0.31864842630568
0.30935475372132804
0.2910753857521784
0.29343265295028687
0.2935851180837268
0.28626800789719536
0.2812062054872513
0.2667317000173387
0.27049337256522404
0.2746902917112623
0.2727455702565965
0.27049792735349565
Val losses 
0.29535192251205444
0.30468419194221497
0.30627116560935974
0.2526639699935913
0.24912406504154205
0.29469820857048035
0.26777949929237366
0.274582177400589
0.23696058988571167
0.27207428216934204
0.27524593472480774
0.25344422459602356
0.22498422861099243
0.24660509824752808
0.2214481681585312
