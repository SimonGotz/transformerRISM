CONFIGURATION: 
Training time: 178 
lr: 0.001
wd: 0.0001
d_model: 32
n_heads: 16
n_layers: 4
d_ff: 128
batch_size: 128
dropout: 0.0307671677646017
margin: 0.7832234257369561
epsilon: 1e-06
Train losses 
0.4860905478166979
0.4101664839788925
0.3386453230713689
0.29706596496493315
0.27343086447826653
0.2505746040233346
0.21320189500963965
0.21904632206573044
0.2048347422549891
0.20371954940086187
0.19095200074966565
0.190358808220819
0.1929998266142468
0.18582463403080784
0.18791631210682003
Val losses 
0.38997209072113037
0.31830745935440063
0.27938979864120483
0.2328025847673416
0.2344672977924347
0.21383430063724518
0.20851238071918488
0.21819114685058594
0.15295034646987915
0.19621989130973816
0.17014992237091064
0.1690683513879776
0.14695867896080017
0.15445025265216827
0.1450156569480896
