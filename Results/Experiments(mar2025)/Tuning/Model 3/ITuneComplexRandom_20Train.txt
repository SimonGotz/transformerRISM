CONFIGURATION: 
Training time: 213 
lr: 0.001
wd: 0.05
d_model: 32
n_heads: 4
n_layers: 3
d_ff: 2048
batch_size: 32
dropout: 0.25097911617328916
margin: 0.22705530641986854
epsilon: 0.001
Train losses 
0.3207106915967805
0.2831276897873197
0.2779977427635874
0.2719688120058605
0.2277793980070523
0.21443455253328597
0.18605731338262557
0.1693756488604205
0.16127809422356743
0.14886376391564096
0.13838802354676383
0.14034353662814414
0.13764133306486265
0.12885125658341817
0.13079166840229717
Val losses 
0.12424034625291824
0.19481539726257324
0.22420114278793335
0.20637284219264984
0.20897196233272552
0.16155783832073212
0.15660183131694794
0.14598165452480316
0.13467133045196533
0.11216339468955994
0.11464596539735794
0.12201645970344543
0.11361139267683029
0.11105617880821228
0.11675617098808289
