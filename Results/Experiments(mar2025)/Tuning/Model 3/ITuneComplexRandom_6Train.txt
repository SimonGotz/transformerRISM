CONFIGURATION: 
Training time: 314 
lr: 1e-05
wd: 0.0005
d_model: 16
n_heads: 16
n_layers: 3
d_ff: 512
batch_size: 16
dropout: 0.24936663047798374
margin: 0.2700713609228807
epsilon: 1e-08
Train losses 
0.5268063756397793
0.5288573934776443
0.478821211542402
0.4428543491874422
0.4030051081946918
0.3834448273905686
0.3561013572769506
0.35636849786554065
0.3452997723647526
0.34490791959421974
0.32289354628750255
0.3276584975421429
0.33220464921423365
0.33440620854496955
0.33693361393042975
Val losses 
0.19977423548698425
0.19627556204795837
0.1757514327764511
0.17143979668617249
0.1669800579547882
0.15067332983016968
0.15388323366641998
0.13998790085315704
0.14118267595767975
0.14173312485218048
0.149529829621315
0.14261610805988312
0.14632569253444672
0.14753752946853638
0.14751090109348297
