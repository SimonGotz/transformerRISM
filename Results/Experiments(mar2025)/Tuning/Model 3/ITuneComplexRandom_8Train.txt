CONFIGURATION: 
Training time: 173 
lr: 2e-05
wd: 0.0005
d_model: 512
n_heads: 16
n_layers: 3
d_ff: 128
batch_size: 512
dropout: 0.25431991864444886
margin: 0.22271465235953525
epsilon: 0.0001
Train losses 
0.353267627954483
0.35299359261989594
0.3603002905845642
0.34701843857765197
0.340302374958992
0.3434655487537384
0.3283848106861115
0.33304027020931243
0.3372192561626434
0.3294959723949432
0.3353113055229187
0.31772342026233674
0.30417572557926176
0.3265556186437607
0.3040033906698227
Val losses 
0.2791103422641754
0.2799292504787445
0.24377098679542542
0.30214494466781616
0.24913273751735687
0.2868616282939911
0.2535737156867981
0.2785661518573761
0.2632041871547699
0.2790403664112091
0.2565097510814667
0.2859351336956024
0.27369096875190735
0.26511895656585693
0.2742670774459839
