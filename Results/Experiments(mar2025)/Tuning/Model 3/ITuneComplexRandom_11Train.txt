CONFIGURATION: 
Training time: 142 
lr: 0.002
wd: 0.001
d_model: 64
n_heads: 2
n_layers: 3
d_ff: 128
batch_size: 256
dropout: 0.18491573509567444
margin: 0.2994084935515022
epsilon: 1e-05
Train losses 
0.41784764187676565
0.29478722455955686
0.22420949737230936
0.18855326445329756
0.17483549813429514
0.17028643935918808
0.15498588979244232
0.1434546797758057
0.1345945955032394
0.13411454395169303
0.12932764490445456
0.12444656164873213
0.13053793673004424
0.11907395543087096
0.1285295177783285
Val losses 
0.20735107362270355
0.1830066591501236
0.15113186836242676
0.15052920579910278
0.13624179363250732
0.16026067733764648
0.12795259058475494
0.11507771909236908
0.11766117811203003
0.10392050445079803
0.1188010722398758
0.09599801898002625
0.10436197370290756
0.10563178360462189
0.10616645961999893
