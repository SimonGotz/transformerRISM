CONFIGURATION: 
Training time: 167 
lr: 0.0002
wd: 0.0001
d_model: 128
n_heads: 4
n_layers: 2
d_ff: 2048
batch_size: 16
dropout: 0.2771650814372191
margin: 0.3330968124675397
epsilon: 1e-06
Train losses 
0.4845330197470529
0.36878819363457815
0.3150146464790617
0.28048438131809234
0.23886157640389033
0.23600298770836423
0.23530873468944005
0.2075342594725745
0.19849640701498303
0.19060883530548642
Val losses 
0.23016253113746643
0.2179938703775406
0.3048633337020874
0.27226322889328003
0.27053317427635193
0.23381580412387848
0.23921917378902435
0.21519023180007935
0.22240644693374634
0.2387782633304596
