CONFIGURATION: 
Training time: 109 
lr: 0.002
wd: 0.01
d_model: 256
n_heads: 8
n_layers: 2
d_ff: 256
batch_size: 64
dropout: 0.20674426452897532
margin: 0.39417943033351927
epsilon: 1e-08
Train losses 
0.36445633827269763
0.23131547131757627
0.21982216749383116
0.2200986285661829
0.232753062470891
0.21140327287473898
0.21250579155039515
0.19234122789796743
0.19358335529593215
0.1742198510930456
Val losses 
0.2275819182395935
0.1986425817012787
0.2138376086950302
0.2408462017774582
0.26603060960769653
0.21687595546245575
0.20412448048591614
0.17192678153514862
0.18469081819057465
0.1503499150276184
