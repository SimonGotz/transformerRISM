CONFIGURATION: 
Training time: 108 
lr: 0.0001
wd: 0.001
d_model: 16
n_heads: 16
n_layers: 3
d_ff: 1024
batch_size: 256
dropout: 0.1672957489848937
margin: 0.5505637134121608
epsilon: 1e-05
Train losses 
0.6591684278987703
0.6153442348752703
0.5723156304586501
0.5356202977044242
0.5257009679362887
0.5153516999312809
0.5024877914360592
0.493465876295453
0.49197393371945336
0.4771851414725894
Val losses 
0.32328560948371887
0.33504682779312134
0.3315524756908417
0.33714139461517334
0.3429855704307556
0.32597294449806213
0.3316647410392761
0.3136093318462372
0.3123878240585327
0.3206668794155121
