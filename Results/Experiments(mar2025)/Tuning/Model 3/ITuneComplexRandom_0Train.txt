CONFIGURATION: 
Training time: 216 
lr: 0.0002
wd: 0.001
d_model: 64
n_heads: 16
n_layers: 2
d_ff: 2048
batch_size: 32
dropout: 0.22872339789702245
margin: 0.5036542549017676
epsilon: 1e-07
Train losses 
0.5890389706407274
0.49215985877173285
0.4220242702960968
0.36372155376843046
0.3228239294460842
0.293052847129958
0.2888055774995259
0.2675115042924881
0.25666033012526374
0.27227402942521234
0.25116500833204813
0.2537740010874612
0.23646045578377586
0.23567048085587367
0.238251314163208
Val losses 
0.24629758298397064
0.24288150668144226
0.25866958498954773
0.26704517006874084
0.26331326365470886
0.25000739097595215
0.24104377627372742
0.2232917845249176
0.2387680858373642
0.1971103847026825
0.22019968926906586
0.22499504685401917
0.22218157351016998
0.2176990807056427
0.21755895018577576
