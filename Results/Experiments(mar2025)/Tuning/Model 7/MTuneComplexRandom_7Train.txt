CONFIGURATION: 
Training time: 161 
lr: 2e-05
wd: 0.0005
d_model: 32
n_heads: 8
n_layers: 3
d_ff: 128
batch_size: 128
dropout: 0.06759863129724031
margin: 0.47283744065062444
epsilon: 0.0001
Train losses 
0.41259159667547357
0.42138856094936994
0.4052931202012439
0.40292445033095603
0.3923990573993949
0.38561264477496926
0.38681827658830686
0.3766616603662801
0.3787629139977832
0.36066389915555025
0.3593059137117031
0.35766308875971065
0.35527596986571025
0.37125032585720685
0.3580716328565465
Val losses 
0.2745944857597351
0.2724439203739166
0.28056761622428894
0.27051952481269836
0.2507818341255188
0.27229538559913635
0.2595880329608917
0.25069865584373474
0.26185905933380127
0.23674240708351135
0.2441936731338501
0.2388354390859604
0.24951718747615814
0.24170559644699097
0.25385868549346924
