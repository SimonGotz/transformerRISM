CONFIGURATION: 
Training time: 123 
lr: 1e-05
wd: 0.001
d_model: 16
n_heads: 8
n_layers: 2
d_ff: 512
batch_size: 256
dropout: 0.47663419821444053
margin: 0.9323463338892765
epsilon: 1e-05
Train losses 
1.040785204796564
1.0375418890090216
1.0193329198019845
0.9948770176796686
1.0410745087124051
1.028606238819304
1.0053071606726873
1.0067776895704723
1.016940434773763
1.0203690897850763
Val losses 
0.559996485710144
0.5440511107444763
0.5531026124954224
0.5287973284721375
0.5308403372764587
0.5638702511787415
0.5343106985092163
0.5159955024719238
0.5450531840324402
0.5322721600532532
