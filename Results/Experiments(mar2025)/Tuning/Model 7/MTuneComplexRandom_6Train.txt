CONFIGURATION: 
Training time: 126 
lr: 0.001
wd: 0.1
d_model: 32
n_heads: 4
n_layers: 1
d_ff: 256
batch_size: 256
dropout: 0.02651901195319417
margin: 0.4378600840924349
epsilon: 1e-05
Train losses 
0.347410051595597
0.3286588362285069
0.2917592383566357
0.26440780361493427
0.24958920691694533
0.23802535874503
0.2366993228594462
0.22474466973826998
0.2267524770327977
0.2233439456848871
0.2192630171775818
0.2202422498237519
0.2153759329091935
0.21719001020703996
0.2146617699237097
Val losses 
0.2608257830142975
0.2350088208913803
0.22525988519191742
0.2077307254076004
0.2291681170463562
0.20841556787490845
0.19738616049289703
0.20058047771453857
0.184779554605484
0.18480010330677032
0.20336709916591644
0.1930595338344574
0.18909284472465515
0.1971559375524521
0.18761159479618073
