CONFIGURATION: 
Training time: 281 
lr: 2e-06
wd: 0.0001
d_model: 128
n_heads: 2
n_layers: 3
d_ff: 2048
batch_size: 32
dropout: 0.42142377995278874
margin: 0.23299855507430609
epsilon: 1e-08
Train losses 
0.52562112058912
0.5435300488131387
0.5387540992668697
0.5354578176566532
0.5133763991083418
0.5081794772829328
0.5039867505005428
0.5058837168557303
0.4843185761996678
0.5067915078571864
0.4865197563171387
0.4880398695809501
0.4681299073355539
0.48751233492578777
0.4831368119376046
Val losses 
0.2894294261932373
0.29097989201545715
0.30192917585372925
0.290697306394577
0.26151710748672485
0.2578793466091156
0.26090797781944275
0.2520793378353119
0.28139278292655945
0.2661485970020294
0.28325220942497253
0.2692427337169647
0.2638002336025238
0.27854081988334656
0.26403531432151794
