CONFIGURATION: 
Training time: 227 
lr: 0.0002
wd: 0.0001
d_model: 32
n_heads: 8
n_layers: 2
d_ff: 256
batch_size: 256
dropout: 0.027748937676516205
margin: 0.32213841175510927
epsilon: 1e-05
Train losses 
0.2900163573878152
0.27930938629877
0.25046555059296743
0.21115256065414065
0.1948926839090529
0.18603756952853429
0.1768764349676314
0.1688642856620607
0.16175293780508496
0.162720388954594
0.15515049724351793
0.1503274454956963
0.15541995423180716
0.15670598120916457
0.15507755605947404
Val losses 
0.20148129761219025
0.17514288425445557
0.162774920463562
0.1552894413471222
0.15980634093284607
0.15358087420463562
0.1400812864303589
0.14744624495506287
0.1325538158416748
0.12600074708461761
0.13197113573551178
0.12792593240737915
0.12410586327314377
0.1254217028617859
0.1208539605140686
