CONFIGURATION: 
Training time: 603 
lr: 0.0002
wd: 0.1
d_model: 32
n_heads: 16
n_layers: 3
d_ff: 512
batch_size: 16
dropout: 0.05084730843992541
margin: 0.3698196010678812
epsilon: 0.0001
Train losses 
0.2798095781462533
0.22708498182041303
0.18558347355042185
0.16639043610010829
0.14793668849127634
0.13839466997555325
0.12950118927018983
0.12481212459504604
0.1130106101504394
0.11655369470162051
0.1083118927691664
0.10754480226763657
0.10481250873633793
0.10607469531042235
0.10130948598895755
Val losses 
0.1894758641719818
0.1662781536579132
0.15240922570228577
0.1326746791601181
0.12147002667188644
0.10358984768390656
0.10490074753761292
0.09239163994789124
0.09879082441329956
0.09479902684688568
0.0869578868150711
0.0851508378982544
0.08053271472454071
0.07412569969892502
0.07009918987751007
