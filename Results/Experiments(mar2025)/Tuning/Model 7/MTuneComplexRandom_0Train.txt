CONFIGURATION: 
Training time: 948 
lr: 2e-05
wd: 0.005
d_model: 256
n_heads: 16
n_layers: 3
d_ff: 2048
batch_size: 64
dropout: 0.0704686324229829
margin: 0.3174630527821389
epsilon: 0.0001
Train losses 
0.28353614454296816
0.26501227641242675
0.24590285482077762
0.2063934149584551
0.1915178663771728
0.17712650996172566
0.16909511207506575
0.1555035436290434
0.1487669907938475
0.14922954193476973
0.14555738275421076
0.1467305046731028
0.13963764297893677
0.141162674146137
0.13767889775763983
Val losses 
0.2563213109970093
0.23273570835590363
0.20272338390350342
0.16767679154872894
0.15015193819999695
0.1446298509836197
0.1220964789390564
0.13798335194587708
0.12754258513450623
0.11799675971269608
0.12782400846481323
0.12006902694702148
0.13058754801750183
0.12504665553569794
0.11481475085020065
