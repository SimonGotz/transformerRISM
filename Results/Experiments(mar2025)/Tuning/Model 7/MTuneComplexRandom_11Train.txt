CONFIGURATION: 
Training time: 147 
lr: 0.001
wd: 0.005
d_model: 32
n_heads: 2
n_layers: 1
d_ff: 256
batch_size: 128
dropout: 0.20791412110162033
margin: 0.557345739476187
epsilon: 0.0001
Train losses 
0.6891169901504073
0.6052600242370783
0.5141792366671007
0.4605781512204991
0.42273292569226995
0.4099592254605404
0.4116449501625327
0.3827496496743934
0.37555733184481777
0.37323662846587424
0.37517487517623016
0.39361705544383024
0.3663401125475418
0.36564545298731604
0.37577365442763927
Val losses 
0.37765660881996155
0.3422425389289856
0.3746984601020813
0.38849344849586487
0.34516575932502747
0.3326733410358429
0.33248233795166016
0.34117940068244934
0.3656459152698517
0.3545478880405426
0.3464058041572571
0.31904593110084534
0.33533307909965515
0.35596102476119995
0.35652071237564087
