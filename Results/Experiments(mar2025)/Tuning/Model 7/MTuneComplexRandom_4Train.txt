CONFIGURATION: 
Training time: 210 
lr: 1e-05
wd: 0.005
d_model: 16
n_heads: 8
n_layers: 2
d_ff: 256
batch_size: 256
dropout: 0.13672314212627196
margin: 0.5579588025022142
epsilon: 0.0001
Train losses 
0.5504891929172334
0.5524321652594066
0.5359080348696027
0.540092184430077
0.5344174390747434
0.5241971299761817
0.523155764454887
0.5330026376815069
0.5192967922914595
0.5165620034649259
0.5209422863665081
0.5218325867539361
0.5259774469193959
0.5348034699757894
0.52611291266623
Val losses 
0.31072449684143066
0.2979287803173065
0.30204880237579346
0.31314197182655334
0.30190226435661316
0.2878202795982361
0.3131145238876343
0.28380709886550903
0.30714452266693115
0.3038518726825714
0.3093160390853882
0.2908044755458832
0.3045012652873993
0.30131909251213074
0.29503652453422546
