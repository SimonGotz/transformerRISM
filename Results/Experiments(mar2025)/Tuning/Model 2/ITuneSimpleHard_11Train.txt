CONFIGURATION: 
Training time: 106 
lr: 0.001
wd: 0.1
d_model: 16
n_heads: 4
n_layers: 3
d_ff: 256
batch_size: 1024
dropout: 0.01789284373610872
margin: 0.2805973713082915
epsilon: 1e-05
Train losses 
0.4511037111282349
0.39254122972488403
0.33169926404953004
0.2937817871570587
0.2802053987979889
0.2704082131385803
0.2762345254421234
0.2783200562000275
0.27382348775863646
0.27738032937049867
0.2616493970155716
0.2662182688713074
0.26282737255096433
0.2729693651199341
0.26562095880508424
Val losses 
0.2927219271659851
0.24810932576656342
0.23225507140159607
0.212876096367836
0.21839912235736847
0.21884790062904358
0.21160314977169037
0.21722811460494995
0.2202470451593399
0.22225716710090637
0.22164113819599152
0.21343004703521729
0.2160712033510208
0.21481356024742126
0.21610333025455475
