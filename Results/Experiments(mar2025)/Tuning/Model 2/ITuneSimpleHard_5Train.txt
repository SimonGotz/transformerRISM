CONFIGURATION: 
Training time: 115 
lr: 0.0001
wd: 0.005
d_model: 256
n_heads: 8
n_layers: 3
d_ff: 1024
batch_size: 1024
dropout: 0.06999502538640051
margin: 0.1344536107242282
epsilon: 1e-05
Train losses 
0.4007625937461853
0.3870438277721405
0.3603184223175049
0.33150580525398254
0.2958069920539856
0.2558724880218506
0.23594556748867035
0.2176653891801834
0.2073413223028183
0.2152466207742691
0.20396788418293
0.2005748689174652
0.19556767642498016
0.19568735957145691
0.1913781613111496
Val losses 
0.2164699286222458
0.20933809876441956
0.19531306624412537
0.1776805967092514
0.16363532841205597
0.1462596207857132
0.14484892785549164
0.12654149532318115
0.13318778574466705
0.11809831857681274
0.1292780339717865
0.12376844882965088
0.12288222461938858
0.12316718697547913
0.12515616416931152
