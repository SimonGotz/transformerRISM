CONFIGURATION: 
Training time: 106 
lr: 2e-05
wd: 0.0001
d_model: 512
n_heads: 4
n_layers: 1
d_ff: 128
batch_size: 1024
dropout: 0.2569188510217733
margin: 0.6108213152587284
epsilon: 1e-08
Train losses 
0.7751353144645691
0.8021571040153503
0.7843987345695496
0.8204470992088317
0.7902488946914673
0.794841206073761
0.8099433898925781
0.8027378678321838
0.8139298915863037
0.8007090091705322
0.7991763234138489
0.8055783271789551
0.7990156769752502
0.7969038963317872
0.7886672019958496
Val losses 
0.5382314920425415
0.5380329489707947
0.5295363068580627
0.5424115061759949
0.5383384227752686
0.5360126495361328
0.517277181148529
0.5220302939414978
0.5500746369361877
0.5215779542922974
0.530110239982605
0.5004512667655945
0.5297858715057373
0.5006231069564819
0.5158935189247131
