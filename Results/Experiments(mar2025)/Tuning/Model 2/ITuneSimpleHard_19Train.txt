CONFIGURATION: 
Training time: 63 
lr: 2e-06
wd: 0.05
d_model: 256
n_heads: 8
n_layers: 2
d_ff: 256
batch_size: 1024
dropout: 0.40746504571424896
margin: 0.2355109535306033
epsilon: 1e-06
Train losses 
0.5701882243156433
0.6000994801521301
0.5753540992736816
0.5424814820289612
0.5636131048202515
0.5804670572280883
0.5875704884529114
0.5607434153556824
0.5990038871765136
0.5590463876724243
Val losses 
0.30933457612991333
0.2932528853416443
0.3078053891658783
0.27467697858810425
0.2882184684276581
0.2902733385562897
0.2932133078575134
0.29172104597091675
0.2919289171695709
0.2995457053184509
