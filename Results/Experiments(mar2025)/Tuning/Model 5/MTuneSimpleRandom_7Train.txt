CONFIGURATION: 
Training time: 171 
lr: 1e-06
wd: 0.005
d_model: 16
n_heads: 2
n_layers: 1
d_ff: 128
batch_size: 32
dropout: 0.05776437163078402
margin: 0.2956132625524084
epsilon: 1e-08
Train losses 
0.3888523055825915
0.38545885579926625
0.3891575517824718
0.3786782992737634
0.37388950075422017
0.38854829064437324
0.38513495436736517
0.3812378282206399
0.3752834552526474
0.3879608588559287
0.38057158734117236
0.37240286537579126
0.382871732711792
0.3850757115227835
0.381578984771456
Val losses 
0.2697811424732208
0.25745218992233276
0.259061336517334
0.2551039457321167
0.2500794529914856
0.2619588077068329
0.25468307733535767
0.25212952494621277
0.2602618634700775
0.2764127254486084
0.2533247470855713
0.24845826625823975
0.2452198565006256
0.24972404539585114
0.24560578167438507
