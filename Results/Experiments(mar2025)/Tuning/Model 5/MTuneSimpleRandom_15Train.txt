CONFIGURATION: 
Training time: 244 
lr: 0.001
wd: 0.05
d_model: 32
n_heads: 8
n_layers: 4
d_ff: 128
batch_size: 256
dropout: 0.41396534830599285
margin: 0.11403784210454035
epsilon: 1e-07
Train losses 
0.4641535310518174
0.3975326319535573
0.3320746024449666
0.2666194885969162
0.2568697439772742
0.2370116746141797
0.22224494034335726
0.21981536561534518
0.21147130855492183
0.20676685869693756
Val losses 
0.19214029610157013
0.13658741116523743
0.09804023802280426
0.08478669077157974
0.08130252361297607
0.07904582470655441
0.08002709597349167
0.08008689433336258
0.0799533799290657
0.07935304939746857
