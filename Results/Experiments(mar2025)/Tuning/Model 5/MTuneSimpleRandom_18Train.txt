CONFIGURATION: 
Training time: 185 
lr: 0.002
wd: 0.001
d_model: 32
n_heads: 4
n_layers: 3
d_ff: 512
batch_size: 64
dropout: 0.15752264725784865
margin: 0.3206097201917967
epsilon: 1e-07
Train losses 
0.3962494823439368
0.31902096566112564
0.28309573592810794
0.24602019444279288
0.22681079924791708
0.19521580430968055
0.18009721667602144
0.16717167113019132
0.16266947153998518
0.15455533349993586
0.1441643509542805
0.14402995524050174
0.1349356605232447
0.1363088225667504
0.13240314805987238
Val losses 
0.2276124805212021
0.22040662169456482
0.20607928931713104
0.17953594028949738
0.182215616106987
0.1452290564775467
0.13997668027877808
0.1544046550989151
0.13087467849254608
0.12551771104335785
0.11804954707622528
0.1240396723151207
0.11790736764669418
0.10243622958660126
0.11201217770576477
