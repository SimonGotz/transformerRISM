CONFIGURATION: 
Training time: 2815 
lr: 2e-05
wd: 0.0001
d_model: 256
n_heads: 2
n_layers: 3
d_ff: 128
batch_size: 512
dropout: 0.02096315393710213
margin: 0.6327634699097563
epsilon: 0.0001
Train losses 
0.565948897600174
0.5862541496753693
0.6093492925167083
0.5655502021312714
0.543945437669754
0.5505138397216797
0.5540944516658783
0.5144707351922989
0.5219643771648407
0.519163966178894
Val losses 
0.5857699513435364
0.5760865211486816
0.5886577367782593
0.5229292511940002
0.5850438475608826
0.5301137566566467
0.5015743374824524
0.5159898996353149
0.4910716712474823
0.5001009702682495
