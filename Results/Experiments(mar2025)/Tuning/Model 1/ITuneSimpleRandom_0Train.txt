CONFIGURATION: 
Training time: 106 
lr: 0.002
wd: 0.1
d_model: 256
n_heads: 4
n_layers: 2
d_ff: 2048
batch_size: 256
dropout: 0.011017728687244321
margin: 0.4587309961166355
epsilon: 1e-05
Train losses 
0.32801892005261923
0.21809856593608856
0.19057540169784
0.18784926618848527
0.1678030714392662
0.15410826603571573
0.12782908905120122
0.1147367503671419
0.10483550333550998
0.10020287476834797
0.09070538498816036
0.0788561822403045
0.07352048708569436
0.0650041452830746
0.06070843392184803
Val losses 
0.25618940591812134
0.18217454850673676
0.17485690116882324
0.17249737679958344
0.15848587453365326
0.13179165124893188
0.11631827801465988
0.11012332141399384
0.10851824283599854
0.08478105813264847
0.08301939815282822
0.06305542588233948
0.061258334666490555
0.05113201588392258
0.05689270421862602
