CONFIGURATION: 
Training time: 209 
lr: 1e-05
wd: 0.01
d_model: 32
n_heads: 16
n_layers: 2
d_ff: 512
batch_size: 16
dropout: 0.3505843519954477
margin: 0.3733677571142275
epsilon: 1e-05
Train losses 
0.6039317665781294
0.5906749047977584
0.5846255918911525
0.5824222490617207
0.558633311859199
0.5591376635857991
0.5422899242384093
0.5190093759553773
0.5258933387909617
0.5203158847774778
0.5108411678671837
0.5083229266745704
0.5024474442430905
0.5234855496031897
0.5091047360215868
Val losses 
0.3206028938293457
0.30712878704071045
0.3199407756328583
0.3150486350059509
0.2939160466194153
0.3026695251464844
0.31072551012039185
0.30141544342041016
0.3038592040538788
0.2891416549682617
0.2882525622844696
0.3018108904361725
0.285815566778183
0.27985554933547974
0.2887057960033417
