CONFIGURATION: 
Training time: 98 
lr: 0.001
wd: 0.001
d_model: 32
n_heads: 8
n_layers: 2
d_ff: 256
batch_size: 512
dropout: 0.2143074619052297
margin: 0.3282379160159381
epsilon: 0.0001
Train losses 
0.5248386442661286
0.48331092298030853
0.4233644187450409
0.3950681805610657
0.3759593844413757
0.3695746213197708
0.3676839619874954
0.3603387624025345
0.3622828423976898
0.35981077551841734
Val losses 
0.2788763642311096
0.2864140272140503
0.25003287196159363
0.24037767946720123
0.24515798687934875
0.23477697372436523
0.2327987104654312
0.2336043417453766
0.23858602344989777
0.2331005334854126
