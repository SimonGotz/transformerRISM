CONFIGURATION: 
Training time: 88 
lr: 1e-06
wd: 0.1
d_model: 16
n_heads: 2
n_layers: 2
d_ff: 2048
batch_size: 512
dropout: 0.33898932540364823
margin: 0.3704665411050592
epsilon: 1e-05
Train losses 
0.6218340814113616
0.6614276170730591
0.6500957846641541
0.6662040948867798
0.6517377853393554
0.6466776311397553
0.6262791872024536
0.6208853781223297
0.6199890971183777
0.6268877446651459
Val losses 
0.3262920379638672
0.3328198492527008
0.3325343728065491
0.3348008394241333
0.33550992608070374
0.3374931514263153
0.32165586948394775
0.32773128151893616
0.3346409797668457
0.32851091027259827
