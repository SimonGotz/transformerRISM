CONFIGURATION: 
Training time: 107 
lr: 2e-06
wd: 0.005
d_model: 16
n_heads: 8
n_layers: 2
d_ff: 2048
batch_size: 64
dropout: 0.4906677986682925
margin: 0.21944407485520304
epsilon: 0.001
Train losses 
0.5405708143765899
0.5627281251309932
0.5471670326145216
0.5580791310332287
0.5312898970883468
0.5168051575792247
0.5193433802703331
0.5376394212931052
0.5249154382738573
0.520393138644339
Val losses 
0.24164462089538574
0.2501504123210907
0.2365824580192566
0.2507065534591675
0.2373535931110382
0.2484818994998932
0.21310687065124512
0.228006973862648
0.2288544923067093
0.2390715330839157
