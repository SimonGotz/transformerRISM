CONFIGURATION: 
Training time: 208 
lr: 1e-06
wd: 0.0001
d_model: 32
n_heads: 8
n_layers: 2
d_ff: 2048
batch_size: 512
dropout: 0.17961217642606292
margin: 0.482470666426209
epsilon: 1e-06
Train losses 
0.6974176526069641
0.6655148684978485
0.692088919878006
0.657571679353714
0.6817479491233825
0.6949642479419709
0.681600707769394
0.6869185388088226
0.6587805092334748
0.6993482232093811
0.6518783569335938
0.6656777501106262
0.6657325208187104
0.6598013013601303
0.666698831319809
Val losses 
0.258075475692749
0.2738780379295349
0.28307870030403137
0.2752247452735901
0.2917895019054413
0.25478288531303406
0.28389468789100647
0.2650393843650818
0.2606363892555237
0.2660735845565796
0.2853618860244751
0.2755934000015259
0.27789604663848877
0.26262590289115906
0.2681274116039276
