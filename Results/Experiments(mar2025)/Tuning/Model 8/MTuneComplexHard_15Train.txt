CONFIGURATION: 
Training time: 86 
lr: 2e-05
wd: 0.0005
d_model: 128
n_heads: 8
n_layers: 2
d_ff: 512
batch_size: 512
dropout: 0.06342381810281145
margin: 0.5473465131984635
epsilon: 0.0001
Train losses 
0.8099407851696014
0.7947583794593811
0.7482588648796081
0.7420085608959198
0.7817353487014771
0.7904580175876618
0.7561039805412293
0.7993119537830353
0.7355131328105926
0.7110622107982636
Val losses 
0.3196876049041748
0.3086898624897003
0.33712685108184814
0.3033002018928528
0.3313046395778656
0.3188324570655823
0.30654945969581604
0.30712366104125977
0.32344624400138855
0.3189857006072998
