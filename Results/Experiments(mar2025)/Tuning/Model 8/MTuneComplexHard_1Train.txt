CONFIGURATION: 
Training time: 102 
lr: 0.0001
wd: 0.0001
d_model: 128
n_heads: 2
n_layers: 4
d_ff: 128
batch_size: 512
dropout: 0.322071706059038
margin: 0.3973975496038318
epsilon: 1e-06
Train losses 
0.6865260243415833
0.6924005091190338
0.65957812666893
0.6585761547088623
0.5838155746459961
0.597511687874794
0.5459629535675049
0.5601817607879639
0.579915001988411
0.5443735688924789
0.5410120993852615
0.520046728849411
0.5210017204284668
0.5474965035915375
0.5188202500343323
Val losses 
0.2815062403678894
0.30880630016326904
0.31405484676361084
0.2999550402164459
0.27075672149658203
0.29021185636520386
0.2636595368385315
0.26854637265205383
0.2652483582496643
0.2894175946712494
0.2690001130104065
0.24768373370170593
0.2917100787162781
0.2632485628128052
0.2786825895309448
