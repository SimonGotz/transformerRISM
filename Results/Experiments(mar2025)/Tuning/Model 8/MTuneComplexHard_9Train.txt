CONFIGURATION: 
Training time: 362 
lr: 0.002
wd: 0.001
d_model: 256
n_heads: 8
n_layers: 4
d_ff: 512
batch_size: 512
dropout: 0.19636596255669625
margin: 0.2010657848212919
epsilon: 1e-06
Train losses 
0.48979848325252534
0.34095274209976195
0.2954172700643539
0.31886876225471494
0.3405733615159988
0.3043806880712509
0.292561286687851
0.2824588492512703
0.28015005886554717
0.28345730900764465
Val losses 
0.21504884958267212
0.10584463179111481
0.10224256664514542
0.1424691379070282
0.15301311016082764
0.14445552229881287
0.14350056648254395
0.14753897488117218
0.14642851054668427
0.13435758650302887
