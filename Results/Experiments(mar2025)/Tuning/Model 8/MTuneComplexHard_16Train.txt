CONFIGURATION: 
Training time: 83 
lr: 0.0001
wd: 0.05
d_model: 128
n_heads: 2
n_layers: 1
d_ff: 256
batch_size: 512
dropout: 0.18536115845185624
margin: 0.21191045670576628
epsilon: 0.0001
Train losses 
0.5738891541957856
0.5779098927974701
0.5338262498378754
0.5254305213689804
0.5293326735496521
0.49046937823295594
0.49409369826316835
0.48977820873260497
0.4885269582271576
0.5034112393856048
0.4736374318599701
0.4818199634552002
0.48118954300880434
0.48076153695583346
0.45687811374664306
Val losses 
0.318430632352829
0.35520026087760925
0.3459111154079437
0.33464595675468445
0.2883308231830597
0.29774346947669983
0.30081793665885925
0.3191111385822296
0.31423673033714294
0.31195753812789917
0.30206501483917236
0.3193693459033966
0.32537204027175903
0.29081398248672485
0.32297971844673157
