CONFIGURATION: 
Learning rate: 0.00E+00 
margin: 0.81 
batch_size: 128 
number of layers: 1 
Train losses 
0.6560974445805621
0.5604091580234357
0.5162836104186613
0.5397983144468336
0.5134366692891762
0.5007936340659412
0.4623487275927814
0.4582050976468556
0.44831443856011577
0.42976757928506654
0.4153465023681299
0.40110764129837945
0.36867166988885225
0.34707513896387016
0.3391106909335549
0.3332027276950096
0.3248670087821448
0.32439206740749416
0.30923214132216437
0.2908492135023003
0.28776911256918264
0.28499329890777814
0.2824911724275617
0.27805542945861816
0.2728384441849011
Val losses 
0.6254028252192906
0.6514768174716404
0.6429364000047956
0.6089068949222565
0.7389531305858067
0.6914204699652535
0.6897940465382167
0.6284837829215186
0.6560262101037162
0.5995032063552311
0.6440738822732653
0.6286424249410629
0.6120693747486387
0.5688489867108208
0.5573717185429165
0.5971330787454333
0.5464876123837062
0.5775452426501683
0.5483142541987556
0.5659709764378411
0.5256179975611823
0.5340706727334431
0.569601331438337
0.5401118163551603
0.5404558905533382
