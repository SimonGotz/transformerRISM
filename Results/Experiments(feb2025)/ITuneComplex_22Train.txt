CONFIGURATION: 
lr: 0.002
wd: 0.0001
d_model: 16
n_heads: 2
n_layers: 3
d_ff: 512
batch_size: 1024
dropout: 0.4786667360186163
margin: 0.3677566033206463
epsilon: 1e-05
Train losses 
0.5932174772024155
0.521338626742363
0.4658607058227062
0.4585004299879074
0.4389866292476654
0.4250909239053726
0.4099074602127075
0.41519855707883835
0.4046582318842411
0.3944702483713627
0.3946063928306103
0.3935740627348423
0.38838986679911613
0.38994090259075165
0.3870208151638508
0.37923211604356766
0.37943949177861214
0.35437555238604546
0.3553995229303837
Val losses 
0.24167659878730774
0.21335580945014954
0.25394174456596375
0.269750714302063
0.27876460552215576
0.2764943838119507
0.27835479378700256
0.28239452838897705
0.28218263387680054
0.26682934165000916
0.26176759600639343
0.2611392140388489
0.2590847909450531
0.24480685591697693
0.23669753968715668
0.2277492880821228
0.23270593583583832
0.24650301039218903
0.2576049864292145
