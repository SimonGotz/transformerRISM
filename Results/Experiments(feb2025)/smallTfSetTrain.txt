CONFIGURATION: 
Training time: 7 
lr: 0.001
wd: 0.001
d_model: 32
n_heads: 2
n_layers: 2
d_ff: 512
batch_size: 8
dropout: 0
margin: 0.3
epsilon: 1e-06
Train losses 
0.3252322018146515
0.22870977073907853
0.1827303797006607
0.08053205907344818
0.0848875992000103
0.0787604495882988
0.042512500286102296
0.058859655261039735
0.05006712600588799
0.016624992340803148
0.00443543940782547
0.025384265184402465
0.01613209694623947
0.021324150264263153
0.005829304456710815
0.008628898859024048
0.03187580406665802
0.00010337680578231812
0.0028876990079879762
0.011024609208106995
Val losses 
0.456960529088974
0.21849340200424194
0.18747857213020325
0.12555526196956635
0.12828631699085236
0.01586529240012169
0.023602426052093506
0.00025278329849243164
0.01609090343117714
0.04744905233383179
0.014567057602107525
0.0052183568477630615
0.012035403400659561
0.0
0.04361729323863983
0.013297160156071186
0.0
0.0
0.0
0.0
