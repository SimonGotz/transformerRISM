CONFIGURATION: 
Training time: 994 
lr: 2e-05
wd: 0.05
d_model: 512
n_heads: 8
n_layers: 2
d_ff: 128
batch_size: 2048
dropout: 0.3375652873215958
margin: 0.3582444546858553
epsilon: 1e-08
Train losses 
0.6622401773929596
0.6696006804704666
0.651228666305542
0.6622497588396072
0.6503192037343979
0.6756912469863892
0.6738698929548264
0.6735121011734009
0.6566934287548065
0.6548935025930405
0.6443440318107605
0.6647842824459076
0.65102519094944
0.6459428071975708
0.6623479127883911
0.6543988138437271
0.6455831229686737
0.6690271496772766
0.6283660531044006
0.6495800912380219
0.628792941570282
0.6539212465286255
0.6492438763380051
0.6402389109134674
0.6391148567199707
Val losses 
0.33364343643188477
0.3412221670150757
0.30243897438049316
0.3163033127784729
0.30888837575912476
0.323941707611084
0.3050028681755066
0.3108859956264496
0.30092954635620117
0.30693867802619934
0.2913825213909149
0.2731561064720154
0.3047875761985779
0.29589372873306274
0.2892289161682129
0.27412882447242737
0.29119354486465454
0.31154191493988037
0.3154612183570862
0.3136163353919983
0.31716716289520264
0.2848584055900574
0.31157463788986206
0.30436933040618896
0.26347580552101135
