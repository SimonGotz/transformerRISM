CONFIGURATION: 
Training time: 447 
lr: 0.002
wd: 0.0005
d_model: 256
n_heads: 4
n_layers: 3
d_ff: 1024
batch_size: 2048
dropout: 0.5342455318479616
margin: 0.26962645987893935
epsilon: 0.001
Train losses 
0.5997304320335388
0.5918134450912476
0.5434645712375641
0.4740627482533455
0.4546652138233185
0.447096586227417
0.4504755139350891
0.4361783042550087
0.42484262585639954
0.41801348328590393
0.4180470257997513
0.4060515835881233
0.405579574406147
0.4138643592596054
0.40451501309871674
0.41048484295606613
0.40065719932317734
0.3995657190680504
0.39108777791261673
0.3984879106283188
0.38946282118558884
0.38994453102350235
0.38993368297815323
0.3853764161467552
0.38635168224573135
Val losses 
0.2402702122926712
0.2085856795310974
0.1630679965019226
0.1278969794511795
0.10184234380722046
0.11492409557104111
0.11289989203214645
0.11576861888170242
0.1162061095237732
0.12027586251497269
0.11536930501461029
0.11759635806083679
0.11294294893741608
0.11502741277217865
0.11289554834365845
0.11753816902637482
0.110881507396698
0.11505798995494843
0.11396387219429016
0.10493892431259155
0.11343744397163391
0.1086006760597229
0.10998517274856567
0.1092178076505661
0.11026522517204285
