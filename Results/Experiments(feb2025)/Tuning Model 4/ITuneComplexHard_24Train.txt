CONFIGURATION: 
Training time: 677 
lr: 2e-06
wd: 0.01
d_model: 64
n_heads: 8
n_layers: 4
d_ff: 1024
batch_size: 2048
dropout: 0.02837016356541744
margin: 0.15683225889224453
epsilon: 0.001
Train losses 
0.46449122577905655
0.43392252177000046
0.4411446899175644
0.44998128712177277
0.4448496252298355
0.4474131762981415
0.4595653787255287
0.4619615077972412
0.44936124235391617
0.4246979430317879
0.45383820682764053
0.44185271114110947
0.44786790758371353
0.435984306037426
0.43662069737911224
0.44144143909215927
0.4285677522420883
0.45398224145174026
0.4391543045639992
0.4335567504167557
0.424550399184227
0.4455742612481117
0.4150093346834183
0.4246736094355583
0.4184075817465782
Val losses 
0.17409439384937286
0.18229493498802185
0.17634649574756622
0.17635032534599304
0.17170417308807373
0.18092650175094604
0.1609247922897339
0.17048139870166779
0.17838221788406372
0.17204922437667847
0.1783006191253662
0.1754370629787445
0.18712231516838074
0.1679416447877884
0.15213102102279663
0.17084594070911407
0.17661111056804657
0.16751496493816376
0.17647460103034973
0.1893935352563858
0.18315653502941132
0.18295197188854218
0.15877337753772736
0.1620764434337616
0.1760159432888031
