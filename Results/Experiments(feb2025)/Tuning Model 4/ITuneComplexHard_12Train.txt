CONFIGURATION: 
Training time: 193 
lr: 2e-06
wd: 0.005
d_model: 16
n_heads: 16
n_layers: 4
d_ff: 128
batch_size: 2048
dropout: 0.6215678427796328
margin: 0.40346299515682515
epsilon: 1e-06
Train losses 
0.6894350051879883
0.7190517038106918
0.7237315326929092
0.6686566323041916
0.671283483505249
0.6911046057939529
0.6878441721200943
0.6803179979324341
0.684366837143898
0.6831638216972351
0.6962459832429886
0.6781580299139023
0.6782992482185364
0.676890641450882
0.6750129610300064
0.6760232746601105
0.6823599636554718
0.689908042550087
0.6734300553798676
0.7029003649950027
0.6868767887353897
0.6836767792701721
0.6841709911823273
0.6641757637262344
0.6791628152132034
Val losses 
0.2993936538696289
0.3225618600845337
0.3059496283531189
0.31354665756225586
0.3030199408531189
0.30691730976104736
0.3080637753009796
0.34354168176651
0.3182346224784851
0.3072049915790558
0.3025238811969757
0.31599101424217224
0.31381291151046753
0.30466774106025696
0.3168877363204956
0.30602604150772095
0.2979657053947449
0.3188076317310333
0.31604352593421936
0.3170642554759979
0.3120594024658203
0.3199959099292755
0.3034116327762604
0.3188685476779938
0.29927578568458557
