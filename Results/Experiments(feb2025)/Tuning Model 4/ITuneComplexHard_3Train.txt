CONFIGURATION: 
Training time: 267 
lr: 0.0002
wd: 0.005
d_model: 128
n_heads: 4
n_layers: 1
d_ff: 512
batch_size: 2048
dropout: 0.417172401340798
margin: 0.16499003017702712
epsilon: 0.001
Train losses 
0.5057269483804703
0.5235581174492836
0.544133648276329
0.5299849137663841
0.5012642666697502
0.5048793330788612
0.49489517509937286
0.5012744292616844
0.48641587048768997
0.48972392827272415
0.46996118128299713
0.48141732811927795
0.47110699117183685
0.4647996723651886
0.4814107269048691
0.4590085968375206
0.4522389695048332
0.4689619839191437
0.4729708805680275
0.46595121920108795
0.462404303252697
0.4511231854557991
0.45673250406980515
0.4711887091398239
0.45612338185310364
Val losses 
0.22668033838272095
0.21101978421211243
0.21936076879501343
0.21138595044612885
0.21965377032756805
0.201072096824646
0.19417504966259003
0.19702737033367157
0.19689787924289703
0.19048601388931274
0.18793384730815887
0.18566222488880157
0.1841367483139038
0.17539627850055695
0.19440019130706787
0.1982223093509674
0.183482825756073
0.17330750823020935
0.16162769496440887
0.17698663473129272
0.16605821251869202
0.1564134806394577
0.17924724519252777
0.15861426293849945
0.1849822700023651
