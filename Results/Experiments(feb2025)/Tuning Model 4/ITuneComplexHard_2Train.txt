CONFIGURATION: 
Training time: 133 
lr: 1e-06
wd: 0.1
d_model: 32
n_heads: 16
n_layers: 4
d_ff: 512
batch_size: 2048
dropout: 0.41522629571462066
margin: 0.3827849079450455
epsilon: 0.001
Train losses 
0.682871088385582
0.6785582900047302
0.7065030634403229
0.6798898428678513
0.6857747733592987
0.6895694136619568
0.6690278500318527
0.6809321045875549
0.671001523733139
0.6686902344226837
0.695327490568161
0.6956993937492371
0.6688186079263687
0.65284663438797
0.6797475963830948
0.6879633218050003
0.6699158847332001
0.6534843891859055
0.6813042610883713
Val losses 
0.24968628585338593
0.25313901901245117
0.24340727925300598
0.26488620042800903
0.2592371106147766
0.25615063309669495
0.26301902532577515
0.27349230647087097
0.24281734228134155
0.27020829916000366
0.25887662172317505
0.27892163395881653
0.27164703607559204
0.24996651709079742
0.29120954871177673
0.24327786266803741
0.2569516897201538
0.26172858476638794
0.2670974135398865
