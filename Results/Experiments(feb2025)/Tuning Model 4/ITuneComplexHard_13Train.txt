CONFIGURATION: 
Training time: 332 
lr: 0.001
wd: 0.0005
d_model: 256
n_heads: 8
n_layers: 2
d_ff: 256
batch_size: 2048
dropout: 0.0800339718079398
margin: 0.2934353830219245
epsilon: 0.01
Train losses 
0.5573771297931671
0.5390942692756653
0.5330507159233093
0.5336335301399231
0.514173686504364
0.5093746334314346
0.5026313066482544
0.4858167693018913
0.4502028524875641
0.453157015144825
0.43490178138017654
0.4207623824477196
0.44002778828144073
0.42858579754829407
0.421552874147892
0.40429622679948807
0.3947727754712105
0.40508176386356354
0.3934730216860771
0.401118665933609
0.41081552952528
0.40142151713371277
0.399743877351284
0.3880315274000168
0.38614024221897125
Val losses 
0.2277761846780777
0.24349439144134521
0.22289663553237915
0.2362602949142456
0.2169499397277832
0.23221518099308014
0.24368971586227417
0.23319414258003235
0.24445800483226776
0.24059349298477173
0.21456770598888397
0.20311161875724792
0.19458551704883575
0.21660107374191284
0.21101927757263184
0.20191428065299988
0.20120517909526825
0.18847453594207764
0.1927637755870819
0.19253169000148773
0.1936127096414566
0.18051853775978088
0.19117623567581177
0.18542784452438354
0.20180034637451172
