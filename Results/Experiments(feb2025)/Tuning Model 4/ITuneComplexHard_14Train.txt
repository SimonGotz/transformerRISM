CONFIGURATION: 
Training time: 210 
lr: 0.0001
wd: 0.05
d_model: 128
n_heads: 4
n_layers: 2
d_ff: 256
batch_size: 2048
dropout: 0.7680920815722478
margin: 0.5517895169843375
epsilon: 1e-06
Train losses 
0.7688235938549042
0.772195503115654
0.7562292218208313
0.7581208199262619
0.7794066965579987
0.7947497367858887
0.7832216024398804
0.7711368948221207
0.7751608937978745
0.7511766701936722
0.7507727891206741
0.7555321156978607
0.7485911101102829
0.7540241032838821
0.75292107462883
0.7793796062469482
0.7668636590242386
0.7522411942481995
0.7576271444559097
0.744327649474144
0.7671330571174622
0.7385759651660919
0.7616736590862274
0.7419313341379166
0.7549899518489838
Val losses 
0.29629793763160706
0.3017169237136841
0.3359626233577728
0.32186654210090637
0.3182174563407898
0.30824562907218933
0.3162330687046051
0.2717379033565521
0.30375486612319946
0.3317411541938782
0.3177642524242401
0.2914208769798279
0.31687718629837036
0.30062952637672424
0.30432575941085815
0.29825741052627563
0.29002779722213745
0.322111576795578
0.29983213543891907
0.33653631806373596
0.29916396737098694
0.2950402796268463
0.30916592478752136
0.2912052571773529
0.31112566590309143
