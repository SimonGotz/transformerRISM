CONFIGURATION: 
Training time: 152 
lr: 1e-06
wd: 0.05
d_model: 128
n_heads: 2
n_layers: 1
d_ff: 128
batch_size: 2048
dropout: 0.5909746840349865
margin: 0.33885208878572654
epsilon: 1e-07
Train losses 
0.6654442548751831
0.6602848917245865
0.6537802219390869
0.6783205568790436
0.6566008776426315
0.6449735015630722
0.6578502953052521
0.653871163725853
0.6687323749065399
0.668344035744667
0.6563533395528793
0.6508679687976837
0.6766467839479446
0.6691505610942841
0.6516447961330414
0.6599190980195999
0.6799175292253494
0.6628986448049545
0.6431991159915924
0.6652660965919495
0.6768999248743057
0.6664209067821503
0.6561806350946426
0.6709676384925842
0.6443970501422882
Val losses 
0.3771030008792877
0.40448805689811707
0.3789665400981903
0.3726702332496643
0.3797275722026825
0.36576762795448303
0.3709758222103119
0.3620747923851013
0.4150981903076172
0.3516637682914734
0.3694872260093689
0.37178701162338257
0.4038485586643219
0.37592557072639465
0.3810502886772156
0.3766321539878845
0.37045562267303467
0.3837977647781372
0.375026136636734
0.3602428138256073
0.3961856961250305
0.35218900442123413
0.3714769184589386
0.37268006801605225
0.37286177277565
