CONFIGURATION: 
Training time: 179 
lr: 2e-05
wd: 0.0001
d_model: 32
n_heads: 8
n_layers: 3
d_ff: 512
batch_size: 2048
dropout: 0.023084526837338883
margin: 0.4547054300877501
epsilon: 1e-08
Train losses 
0.5943735241889954
0.6183914393186569
0.5939018577337265
0.5895213335752487
0.5965495705604553
0.5801550298929214
0.5694867223501205
0.5717197507619858
0.5539226233959198
0.5495281219482422
0.5601745694875717
0.5627161115407944
0.5543817281723022
0.5540520548820496
0.5592763423919678
0.5448983907699585
0.5502684563398361
0.5677845925092697
0.5372337847948074
0.535439133644104
0.5347550511360168
0.5505817830562592
0.537349209189415
0.5406704396009445
0.5325963497161865
Val losses 
0.35624492168426514
0.35263583064079285
0.3484993278980255
0.3638511896133423
0.3477470278739929
0.3409242331981659
0.35795333981513977
0.3478891849517822
0.3351862132549286
0.3321269452571869
0.3398681581020355
0.32009053230285645
0.3201434016227722
0.3293401896953583
0.33163440227508545
0.3373868465423584
0.31991681456565857
0.31934186816215515
0.30856987833976746
0.33254775404930115
0.3107708692550659
0.31690487265586853
0.3229673206806183
0.3131289780139923
0.31018975377082825
