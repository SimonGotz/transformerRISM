CONFIGURATION: 
Training time: 203 
lr: 1e-05
wd: 0.01
d_model: 128
n_heads: 8
n_layers: 2
d_ff: 128
batch_size: 2048
dropout: 0.02437554551251866
margin: 0.1206774983537393
epsilon: 1e-05
Train losses 
0.4300001263618469
0.4064370393753052
0.4092465788125992
0.40844952315092087
0.4169531539082527
0.4112495258450508
0.40003595501184464
0.40272393077611923
0.39950544387102127
0.4068503826856613
0.39276599138975143
0.3985655978322029
0.4043932780623436
0.39673593640327454
0.3833260238170624
0.394309937953949
0.3860347345471382
Val losses 
0.20326265692710876
0.18596281111240387
0.18883636593818665
0.16731105744838715
0.20390605926513672
0.19666343927383423
0.1706339567899704
0.20145545899868011
0.18209829926490784
0.1920536607503891
0.17629064619541168
0.1775912046432495
0.18430191278457642
0.17630450427532196
0.17959141731262207
0.1869295984506607
0.18723329901695251
