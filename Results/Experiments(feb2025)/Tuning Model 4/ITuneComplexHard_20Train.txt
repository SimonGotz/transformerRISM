CONFIGURATION: 
Training time: 781 
lr: 2e-06
wd: 0.1
d_model: 128
n_heads: 2
n_layers: 4
d_ff: 256
batch_size: 2048
dropout: 0.7172788144802548
margin: 0.14795858904269688
epsilon: 1e-08
Train losses 
0.4993891343474388
0.5135078355669975
0.5171979367733002
0.5216327980160713
0.496593177318573
0.4945073500275612
0.5291823446750641
0.5233878344297409
0.5110906288027763
0.5006764903664589
0.5078816637396812
0.5053804814815521
0.5160070061683655
0.517794132232666
0.5006839260458946
0.5146165043115616
0.5063963383436203
0.5135359987616539
0.519203320145607
0.5080408006906509
0.5044679194688797
0.5056002363562584
0.5160470455884933
Val losses 
0.25956082344055176
0.25797238945961
0.2423027753829956
0.2422601282596588
0.25048327445983887
0.25665533542633057
0.26895278692245483
0.2642039954662323
0.27732276916503906
0.22403165698051453
0.2622435986995697
0.2824031114578247
0.25601449608802795
0.2492661327123642
0.2534242272377014
0.24557194113731384
0.2563496232032776
0.25114744901657104
0.2755216360092163
0.24690108001232147
0.26051992177963257
0.2632150650024414
0.2694413363933563
