CONFIGURATION: 
lr: 0.001
wd: 0.005
d_model: 512
n_heads: 4
n_layers: 2
d_ff: 512
batch_size: 256
dropout: 0.3943471758251098
margin: 0.25437619730654026
epsilon: 1e-07
Train losses 
0.5522897180282709
0.4314796193079515
0.33912414583292877
0.3437136303294789
0.3483527781385364
0.4343846756400484
0.40420498450597125
0.3923604641899918
0.3831994425166737
0.3829480364467158
0.3742449473250996
0.36530784404639044
0.36076461004488397
0.34535852345553314
0.35097836635329505
0.34785405885089526
0.3389533261458079
0.3402266231450168
Val losses 
0.3547995090484619
0.4465214652674539
0.44811377780778067
0.4352889657020569
0.4909819619996207
0.20215027460030147
0.2983355053833553
0.30843772632735117
0.23661206236907414
0.2772614232131413
0.2558148716177259
0.3384600877761841
0.3687716679913657
0.27975618839263916
0.27441532271248953
0.2940381403480257
0.3049527747290475
0.34469727533204214
