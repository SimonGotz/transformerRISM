CONFIGURATION: 
lr: 2e-05
wd: 0.0005
d_model: 128
n_heads: 16
n_layers: 4
d_ff: 1024
batch_size: 1024
dropout: 0.33542400077351175
margin: 0.899750439570496
epsilon: 0.0001
Train losses 
0.871255449950695
0.8774424940347672
0.8477723076939583
0.8432726114988327
0.8385357707738876
0.8285306915640831
0.8434470370411873
0.8146820440888405
0.8311741352081299
0.8340523391962051
0.8292890638113022
0.8177940174937248
0.8134961426258087
0.8111459836363792
0.8134596198797226
0.7965389341115952
0.815863199532032
0.8064175695180893
0.8025645464658737
0.8023230880498886
0.8013557642698288
0.8014055863022804
0.8032416850328445
0.8020815327763557
0.8051280006766319
Val losses 
0.401462197303772
0.3678644299507141
0.36041259765625
0.36825045943260193
0.40202873945236206
0.36747273802757263
0.41154658794403076
0.43727901577949524
0.42180415987968445
0.3701034188270569
0.3977157175540924
0.3819514214992523
0.3795875608921051
0.3907860517501831
0.3827023506164551
0.3843300938606262
0.39919331669807434
0.38927000761032104
0.3752993941307068
0.3975062370300293
0.37851500511169434
0.37137311697006226
0.3696715831756592
0.38930636644363403
0.3731990158557892
