CONFIGURATION: 
lr: 0.002
wd: 0.1
d_model: 32
n_heads: 8
n_layers: 1
d_ff: 1024
batch_size: 16
dropout: 0.6981934137146342
margin: 0.13700898542193307
epsilon: 0.1
Train losses 
0.5237587322239523
0.5069347352893264
0.45771195077233845
0.4255883581660412
0.4037137471139431
0.3703491569393211
0.3340817107370606
0.30801362665715043
0.28862545161887454
0.2655672379941852
0.25651868333419164
Val losses 
0.15304135278515194
0.13733258253854255
0.13495198429926583
0.10187479247865469
0.09328682422637939
0.07355487788824931
0.07295734777074793
0.07602262832224368
0.07703860240138095
0.07908462995420332
0.0861605253232562
