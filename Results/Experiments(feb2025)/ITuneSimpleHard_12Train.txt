CONFIGURATION: 
lr: 0.001
wd: 0.0005
d_model: 32
n_heads: 16
n_layers: 1
d_ff: 128
batch_size: 256
dropout: 0.3679310217641434
margin: 0.5308385548145359
epsilon: 1e-08
Train losses 
0.7394267609625151
0.7079753713174299
0.6512754342772744
0.6037301168297277
0.5805638233820597
0.5607471375754385
0.6177439978628447
0.5935827872969888
0.5857614585847566
0.5882734060287476
0.5803107438665448
0.5795382351586313
0.567585988478227
0.5646463939637849
0.5682626980723757
0.5679344715494098
0.5702025601358125
0.566857812982617
0.5739626613530245
Val losses 
0.47675647905894686
0.4756160421030862
0.44226709433964323
0.4267956614494324
0.426107508795602
0.42667021070207867
0.42753200020108906
0.4200152116162436
0.4257823143686567
0.43757234300885883
0.4322596277509417
0.4382011081491198
0.42677342891693115
0.4398712473256247
0.43932601383754183
0.42869025468826294
0.43344453402927946
0.4351677213396345
0.44866042477743967
