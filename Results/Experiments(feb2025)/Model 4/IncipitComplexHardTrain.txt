CONFIGURATION: 
Training time: 1707 
lr: 0.001
wd: 0.05
d_model: 1024
n_heads: 16
n_layers: 2
d_ff: 2048
batch_size: 1024
dropout: 0.1865127956905365
margin: 0.43601381067010553
epsilon: 1e-05
Train losses 
0.7042323797941208
0.6027546674013138
0.538216345012188
0.5550070628523827
0.5412721186876297
0.5279044732451439
0.539797767996788
0.5219164341688156
0.5503663644194603
0.5285277850925922
0.527663491666317
0.5256875604391098
0.4917592220008373
0.5005553998053074
0.5149696245789528
0.5179659649729729
0.5061429999768734
0.5132285803556442
0.49882493540644646
0.4928358197212219
0.4913771376013756
0.49310676753520966
0.491656381636858
0.48498085886240005
0.47993278875947
0.48431888595223427
0.45137302950024605
0.47951795533299446
0.45925258472561836
0.45536934956908226
Val losses 
0.30960822105407715
0.21526792645454407
0.21351751685142517
0.23502132296562195
0.23154371976852417
0.24416813254356384
0.25030261278152466
0.2805579900741577
0.2553011178970337
0.22628051042556763
0.22775642573833466
0.25887739658355713
0.3012496829032898
0.25745922327041626
0.24092698097229004
0.20621441304683685
0.2348770648241043
0.23547768592834473
0.24076783657073975
0.28167495131492615
0.304694801568985
0.3125387132167816
0.33324235677719116
0.28942370414733887
0.3785817623138428
0.3396783173084259
0.31822696328163147
0.34032246470451355
0.36990228295326233
0.3168802559375763
