CONFIGURATION: 
lr: 0.002
wd: 0.001
d_model: 128
n_heads: 2
n_layers: 3
d_ff: 2048
batch_size: 128
dropout: 0.008190718449561275
margin: 0.5460624946914691
epsilon: 1e-08
Train losses 
0.3228337451148389
0.24632321476046717
0.25851523398018594
0.30671794356694865
0.21126566704974245
0.23177131565649117
0.19610332786592086
0.4758184596673766
0.4249769535972111
0.45585256147740494
0.4245354942421415
0.43683299956037036
0.41962253202253313
0.44030400309989703
0.41065397169162976
0.42016036964174525
0.39683160652865224
0.4088441925262337
0.413561131082364
0.395259821148061
0.4122633217875637
0.4113176336039358
0.4130123675759159
0.4502468803035679
0.4467749608986413
Val losses 
0.36631094557898386
0.3855565594775336
0.40430336552006857
0.3662591576576233
0.33843676320144106
0.3378311289208276
0.34658553664173397
0.43116552914891926
0.3975267878600529
0.39821176656654905
0.35987077014786856
0.43022034210818155
0.35264194863183157
0.36346268015248434
0.39270786941051483
0.3844184471028192
0.3701826184988022
0.37475103778498514
0.39253614630017963
0.3777634309870856
0.3684962434428079
0.3650279279266085
0.3608721728835787
0.31007932126522064
0.325136552963938
