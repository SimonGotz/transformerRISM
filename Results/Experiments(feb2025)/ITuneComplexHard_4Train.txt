CONFIGURATION: 
lr: 2e-06
wd: 0.005
d_model: 32
n_heads: 4
n_layers: 4
d_ff: 128
batch_size: 1024
dropout: 0.3676641437601248
margin: 0.5417925410699335
epsilon: 0.001
Train losses 
0.7566297426819801
0.7417961582541466
0.7473304867744446
0.7609357461333275
0.7566652074456215
0.7530432865023613
0.801264263689518
0.7975082919001579
0.8083446249365807
0.7982988804578781
0.7940136343240738
0.8074254170060158
0.8041740357875824
0.7860655710101128
0.815680481493473
0.7985935509204865
0.7953266575932503
0.8069667294621468
0.8138166144490242
0.7950350269675255
0.7950783744454384
0.7940373569726944
0.8087250664830208
0.8097846060991287
0.7915248721837997
Val losses 
0.33687373995780945
0.32121866941452026
0.2952961325645447
0.31714290380477905
0.31180405616760254
0.35436463356018066
0.31887564063072205
0.33305928111076355
0.2930401861667633
0.3186502754688263
0.31491824984550476
0.3148236572742462
0.3355996608734131
0.29114940762519836
0.3016384243965149
0.3080177903175354
0.3034374713897705
0.31562092900276184
0.3396769165992737
0.3083045482635498
0.3060203492641449
0.30379799008369446
0.2883399426937103
0.2915114462375641
0.3185179829597473
