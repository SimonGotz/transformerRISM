CONFIGURATION: 
Training time: 6 
lr: 0.001
wd: 0.001
d_model: 32
n_heads: 2
n_layers: 2
d_ff: 512
batch_size: 8
dropout: 0
margin: 0.3
epsilon: 1e-06
Train losses 
0.14193298071622848
0.13273624330759048
0.05721377730369568
0.07542653530836105
0.05648723840713501
0.011485868692398071
0.028270994126796723
0.027745582163333893
0.032923704385757445
0.0351787693798542
0.009133212268352509
0.006572066247463227
0.005022841691970825
0.01890089064836502
0.0095300555229187
0.0025788620114326477
0.007981489598751067
0.0031673982739448547
0.006935243308544159
0.001583060622215271
Val losses 
0.2296624779701233
0.08828960359096527
0.016373760998249054
0.05652235448360443
0.038424842059612274
0.048893384635448456
0.04828852415084839
0.02974017523229122
0.051675643771886826
0.0042160749435424805
0.029047422111034393
0.03158844634890556
0.009389049373567104
0.0005015333299525082
0.029842309653759003
0.0
0.0
0.00027670463896356523
0.0
0.0
