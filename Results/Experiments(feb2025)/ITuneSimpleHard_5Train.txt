CONFIGURATION: 
lr: 0.0002
wd: 0.005
d_model: 32
n_heads: 4
n_layers: 2
d_ff: 256
batch_size: 64
dropout: 0.14541295921881067
margin: 0.28250877779931133
epsilon: 0.01
Train losses 
0.43183774363111566
0.42424798950001047
0.4193799513357657
0.3935612855134187
0.3783574448691474
0.35777564644813536
0.3472736084902728
0.5265794339003387
0.48761039906077913
0.4670411452099129
0.4476863673439732
0.43614673261289244
0.41974102346985426
0.420413159220307
0.39869598415162827
0.4001148153234411
0.39661007589764063
0.3848034006577951
0.38766713252773993
0.38250018578988537
0.3760546690887875
0.3814804829933025
0.37568758328755697
0.3754215556162375
0.3704700255835498
Val losses 
0.34764820763043
0.32863788093839374
0.31783313197749
0.33156793298465864
0.2976131098611014
0.2948634369032724
0.308646348970277
0.29054126941732
0.2762612923979759
0.2784542569092342
0.2550861319260938
0.2431782058307103
0.2447845616510936
0.22994427223290717
0.23403126799634524
0.24899520192827498
0.24540882664067404
0.23253077641129494
0.23145864478179387
0.23028344873871123
0.23305178274001395
0.23796746720160758
0.23446346819400787
0.23652845195361547
0.22903769995485032
