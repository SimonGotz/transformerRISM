CONFIGURATION: 
lr: 1e-05
wd: 0.01
d_model: 512
n_heads: 4
n_layers: 3
d_ff: 256
batch_size: 16
dropout: 0.6437854124056347
margin: 0.751471796934074
epsilon: 1e-07
Train losses 
0.8972013665570153
0.9096565423188386
0.9067445211940341
0.9115326647405271
0.887960527561329
0.9012986602606596
0.9441396865579817
0.917003889216317
0.9055991135261677
0.9187413688059206
0.9116659859816233
0.9178024488466757
0.9110370583004421
0.9073669934714282
0.8952928852151941
0.9126533192616922
0.8964387385933488
0.9114514319985001
0.9068453565791801
0.8980078562542244
0.897219200929006
0.9032739577470003
0.8985103967013183
0.8978067645320186
0.9124243881967332
Val losses 
0.6212426138960797
0.6254541365996651
0.6109064832977626
0.6116095589554829
0.5645150423049927
0.6170523669408715
0.5765185770781144
0.5800387035245481
0.5933598549469657
0.5873657102170198
0.5909713356391243
0.6040781389112058
0.5594201533690742
0.5568413288696953
0.5594724235327347
0.5073071402052175
0.5828604910684668
0.5583068697348885
0.543555444219838
0.5421760154807049
0.5689374607542287
0.5559329628944397
0.561011731106302
0.5299668799275937
0.5813723994337994
