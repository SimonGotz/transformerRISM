CONFIGURATION: 
lr: 0.0002
wd: 0.0001
d_model: 64
n_heads: 2
n_layers: 2
d_ff: 1024
batch_size: 256
dropout: 0.4146766721658945
margin: 0.4420737412083359
epsilon: 0.0001
Train losses 
0.6549923835378705
0.6102005026557229
0.5759986982201085
0.5337418362949834
0.4872809747854869
0.4802679220835368
0.4918539487954342
0.5203484721256025
0.5105037327968713
0.5005755207755349
0.5079638867667227
0.50729557149338
0.5103013380007311
0.5030102522084208
0.4989386399586995
0.49495769901709125
0.49511137424093304
0.4959624138745395
0.493573245677081
0.5024380485216776
0.49161900625084387
0.4867513884197582
0.498380827181267
0.4898559631723346
0.4884048375216397
Val losses 
0.29856797627040316
0.28562937889780315
0.26512633902685984
0.27338479246412006
0.2470330787556512
0.24322645366191864
0.2571998281138284
0.25660658947059084
0.24872658721038274
0.23939052011285508
0.2166173074926649
0.2411236720425742
0.22161605102675302
0.22287409007549286
0.23212621467454092
0.2179133210863386
0.22515266069344111
0.21631440307412828
0.23460124220166886
0.22912503566060746
0.22932749135153635
0.23981085206781114
0.23147302440234593
0.2163980177470616
0.2166705301829747
