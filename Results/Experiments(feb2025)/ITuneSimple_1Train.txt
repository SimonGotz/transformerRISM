CONFIGURATION: 
Learning rate: 2.58E-07 
margin: 0.81 
batch_size: 32 
number of layers: 3 
Train losses 
0.6560974445805621
0.5604091580234357
0.5162836104186613
0.5397983144468336
0.5134366692891762
0.5007936340659412
0.4623487275927814
0.4582050976468556
0.44831443856011577
0.42976757928506654
0.4153465023681299
0.40110764129837945
0.36867166988885225
0.34707513896387016
0.3391106909335549
0.3332027276950096
0.3248670087821448
0.32439206740749416
0.30923214132216437
0.2908492135023003
0.28776911256918264
0.28499329890777814
0.2824911724275617
0.27805542945861816
0.2728384441849011
0.6166716003859485
0.6181993908352322
0.6150901563741543
0.6225860257943471
0.6118744820356369
0.599611950914065
0.5964694879673146
0.6142686588896645
0.6229566762844722
0.5918429164974778
0.5935037534545969
0.5880218547803384
0.6032503099353225
0.5830843145096744
0.585226571559906
0.583820789831656
0.5893806211374424
Val losses 
0.5921086229776081
0.6351665467546698
0.6117758013700184
0.6755713736801817
0.629204942991859
0.6433187163712686
0.6343355884677485
0.6325863552720923
0.6559561611267558
0.651336856055678
0.6432580602796454
0.639765341030924
0.6388965416372868
0.5974346995353699
0.6003254191917285
0.6174235631499374
0.6249716072751764
