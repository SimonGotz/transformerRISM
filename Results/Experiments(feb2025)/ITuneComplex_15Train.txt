CONFIGURATION: 
lr: 0.0001
wd: 0.1
d_model: 256
n_heads: 4
n_layers: 4
d_ff: 512
batch_size: 16
dropout: 0.5429275732971682
margin: 0.8748677123419862
epsilon: 0.0001
Train losses 
0.9153325511349573
0.9000266014425843
0.8745713314524404
0.8022504072498392
0.6921003467506832
0.6284841950292941
0.5969236956702338
0.5729327085945342
0.5532042926108396
0.5506391732781022
0.5399885868584668
0.5330532377516782
0.5115838321270766
0.506420671387955
0.48589851370564213
0.48902273961791287
0.4862181300366366
0.4713670148893639
0.48686337228174564
0.4734566582573785
0.48700782976768636
0.46384664431766226
0.4658075827139395
0.4636493776683454
0.47345784935686325
Val losses 
0.46416809792103975
0.41631386642870694
0.431133838062701
0.44655456776204316
0.6846596393896186
0.7404670107623805
0.6622267666070357
0.6577335124430449
0.6789300433967425
0.7027828763360563
0.6298183078351228
0.6965864479541779
0.6878639971432479
0.6404238682726155
0.6451517362957415
0.5585414614366448
0.6411853752706362
0.580657898472703
0.5869798373916875
0.6681981735903284
0.6054830374925033
0.6005090033230575
0.5365666114765665
0.5615961875604547
0.6136588750973991
