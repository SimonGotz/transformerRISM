CONFIGURATION: 
Learning rate: 1.48E-07 
margin: 0.39 
batch_size: 128 
number of layers: 3 
Train losses 
0.6560974445805621
0.5604091580234357
0.5162836104186613
0.5397983144468336
0.5134366692891762
0.5007936340659412
0.4623487275927814
0.4582050976468556
0.44831443856011577
0.42976757928506654
0.4153465023681299
0.40110764129837945
0.36867166988885225
0.34707513896387016
0.3391106909335549
0.3332027276950096
0.3248670087821448
0.32439206740749416
0.30923214132216437
0.2908492135023003
0.28776911256918264
0.28499329890777814
0.2824911724275617
0.27805542945861816
0.2728384441849011
0.6166716003859485
0.6181993908352322
0.6150901563741543
0.6225860257943471
0.6118744820356369
0.599611950914065
0.5964694879673146
0.6142686588896645
0.6229566762844722
0.5918429164974778
0.5935037534545969
0.5880218547803384
0.6032503099353225
0.5830843145096744
0.585226571559906
0.583820789831656
0.5893806211374424
0.2841048687696457
0.2757000423139996
0.3333986985462683
0.44338882918711064
0.49696483501681576
0.5444508751233419
0.5158270257490652
0.5241453742539441
0.514414518630063
0.50906857141742
0.5067411096007736
0.5054187931396343
0.4998836241386555
0.4991898512398755
0.490707426821744
0.4939555397740117
0.4952064127833755
0.49551369349161783
0.49045156902737086
0.491036550866233
0.6652801483869553
0.6721246466040611
0.6672620624303818
0.654623493552208
0.6457553505897522
0.6603094786405563
0.6560669243335724
0.6429185420274734
0.6388573795557022
0.6279082223773003
0.6488242149353027
0.6279678046703339
0.6312614008784294
0.6411639302968979
0.620943546295166
0.6312003210186958
0.6202041432261467
0.622772328555584
0.6185212284326553
0.6215010359883308
0.6148229688405991
0.6158554926514626
0.6114488616585732
0.6227817237377167
0.6153039857745171
0.41246336334281497
0.4040058739759304
0.3843815785867197
0.3711400989029143
0.3548929959535599
0.34742578897211285
0.333303580460725
0.32223128687452385
0.31147145882800775
0.3033260855409834
0.2948933889468511
0.2926469801752656
0.2886311888694763
0.2890212798560107
0.19278182199707738
0.20779197834156177
0.29563529094060265
0.3547706098468215
0.3222696849041515
0.29527639553502755
0.2824380158826157
0.2658087577532839
0.2507003684838613
0.2379950632099752
0.2263128916974421
0.21881193115755362
0.21178788802138082
0.206740143812365
0.20018803849816322
0.19939377995000945
0.18438742927930973
0.1876045424905088
0.18248961766560873
0.18557439482322446
0.1795940252089942
0.17411873075697157
0.17091177155574164
0.17361624124977323
0.1717405672426577
0.6196169263786739
0.4633299245878502
0.34743540044184085
0.2984054734309514
0.2523804350031747
0.21665466571295702
0.19528623079812085
0.17642349667019314
0.16772748607176322
0.15053042085082444
0.1430549446079466
0.12619912381525392
0.11896129614777035
0.11034010902599052
0.10679831703503927
0.09318856652136202
0.09224125864329162
0.09273933536476558
0.07695527727957126
0.08185966423264256
0.06651037280206328
0.07694240124137314
0.06370732618702782
0.05811578719704239
0.06545952823426988
0.3955898912095312
0.4026068444572278
0.3997350504149252
0.39058745752519636
0.39366115518470307
0.3897778996780737
0.39692722105268224
0.3811849395730602
0.39430980540033594
0.37716650162170184
0.38585285308645734
0.3760844255561259
0.38133372833479695
0.37372867340472204
0.379442468507966
0.383327297310331
0.390186824015717
0.37387295756767047
0.3804509057037866
0.36730650089569944
Val losses 
0.6195572061198098
0.6412344362054553
0.6576489870037351
0.6357703251498086
0.6343745248658317
0.6444150848048074
0.6203492156096867
0.6039923557213375
0.6387059773717608
0.6293500661849976
0.6143149265221187
0.5953402710812432
0.6183416630540576
0.606366583279201
0.6509403586387634
0.632185989192554
0.6085190687860761
0.6096607404095786
0.6213694981166294
0.6332500960145678
