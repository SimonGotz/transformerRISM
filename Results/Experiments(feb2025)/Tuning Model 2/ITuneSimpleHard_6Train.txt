CONFIGURATION: 
Training time: 299 
lr: 0.001
wd: 0.005
d_model: 32
n_heads: 8
n_layers: 3
d_ff: 512
batch_size: 2048
dropout: 0.1458101753162949
margin: 0.14844872502658107
epsilon: 1e-08
Train losses 
0.452347069978714
0.39137253165245056
0.27514146640896797
0.2301703244447708
0.2344568595290184
0.21807503700256348
0.21409476548433304
0.21532179415225983
Val losses 
0.24975355292319737
0.1884490967698512
0.13245414064614466
0.12265713655388336
0.11592840852929347
0.12109052940905256
0.12393564806958265
0.1240329798220429
