CONFIGURATION: 
Training time: 132 
lr: 0.002
wd: 0.005
d_model: 32
n_heads: 4
n_layers: 2
d_ff: 512
batch_size: 2048
dropout: 0.22353719226952046
margin: 0.6649368438483553
epsilon: 1e-06
Train losses 
0.8285819590091705
0.7514139264822006
0.684443861246109
0.6809354275465012
0.6896187514066696
0.673063337802887
0.6840232759714127
0.6690337210893631
0.682898759841919
0.6775808185338974
0.6789016127586365
0.6703263521194458
0.6797315776348114
0.6766297668218613
0.6707237958908081
0.6753398329019547
0.6776987612247467
0.6778923869132996
0.6772445440292358
0.6795507818460464
0.6730681210756302
0.6672913879156113
0.6791639029979706
0.6748566031455994
0.6688368022441864
Val losses 
0.4911700189113617
0.5040123462677002
0.5462921261787415
0.5881502032279968
0.6078263521194458
0.6111494302749634
0.6163957715034485
0.611290454864502
0.62103670835495
0.6179901361465454
0.6132051944732666
0.6125496625900269
0.6173998713493347
0.6111373901367188
0.6148338317871094
0.6129081845283508
0.610851526260376
0.6117064952850342
0.6053850650787354
0.6117451786994934
0.6162594556808472
0.6101466417312622
0.6075633764266968
0.6132520437240601
0.6085318326950073
