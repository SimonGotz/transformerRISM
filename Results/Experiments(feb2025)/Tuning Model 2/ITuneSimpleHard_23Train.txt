CONFIGURATION: 
lr: 2e-05
wd: 0.0001
d_model: 1024
n_heads: 4
n_layers: 3
d_ff: 1024
batch_size: 128
dropout: 0.7944344007666515
margin: 0.38891355840719793
epsilon: 1e-08
Train losses 
0.6316929041449704
0.6486739338333927
0.6398615801512305
0.6500747168242041
0.6200523340879981
0.6321567256948841
0.6256764224216119
0.6579072217443096
0.652800196142339
0.6406211372631699
0.6354940444675844
0.6401035839052343
0.6509306359646926
0.6354634935286507
0.6592699004642999
0.6456052825522067
0.6456666446443814
0.6381822891199767
0.6381431711253835
0.6468163844364793
0.6342312262129428
0.6384031381180038
0.6483093740335152
0.6372940798303974
0.644779649243426
Val losses 
0.4873171491282327
0.40617176251752035
0.4335799983569554
0.4101240805217198
0.3826353762831007
0.37569937322820934
0.3881636666400092
0.37951130526406424
0.37240331300667356
0.38668787692274365
0.3805424315588815
0.4196546418326242
0.393971575157983
0.39192088161196026
0.3936682215758732
0.3798488144363676
0.43294427011694225
0.3856492340564728
0.4157320133277348
0.4088902345725468
0.3862700973238264
0.3718608724219458
0.408085503748485
0.3888175444943564
0.39985702293259756
