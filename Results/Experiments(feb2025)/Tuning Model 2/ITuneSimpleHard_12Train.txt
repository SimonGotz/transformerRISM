CONFIGURATION: 
Training time: 366 
lr: 2e-06
wd: 0.05
d_model: 32
n_heads: 16
n_layers: 1
d_ff: 2048
batch_size: 2048
dropout: 0.31024447446509573
margin: 0.650480088607299
epsilon: 0.001
Train losses 
0.8393873870372772
0.8476771414279938
0.8558967858552933
0.8389036655426025
0.8402292430400848
0.8300053775310516
0.8237536698579788
0.8259957432746887
0.8421902358531952
0.8314283490180969
0.8550744503736496
0.8331420123577118
0.8500605672597885
0.8363569974899292
0.8265985399484634
0.8400818258523941
0.8179758936166763
0.8371326178312302
0.8331877887248993
0.8274373263120651
0.828668862581253
0.8304473161697388
0.8442906588315964
0.8511743098497391
0.8552966117858887
Val losses 
0.5365385688491153
0.5315109953759233
0.5289636492922395
0.5291034863614701
0.5309117333042757
0.5434814271638356
0.5054877687956049
0.5280837923819667
0.5208041347213077
0.5143760427921157
0.5224488440363682
0.5013029762759588
0.5315424605101138
0.5170469281481511
0.5346573501712628
0.5248962587952163
0.5048312669441805
0.5379018220690248
0.5586647159147752
0.53791193592426
0.5313378886104854
0.5435369258826002
0.5260568261468559
0.5437958415040192
0.5219251075221164
