CONFIGURATION: 
Training time: 558 
lr: 2e-06
wd: 0.0005
d_model: 16
n_heads: 8
n_layers: 2
d_ff: 2048
batch_size: 2048
dropout: 0.17707959319868155
margin: 0.834897002408894
epsilon: 1e-07
Train losses 
0.9743209034204483
0.9940635710954666
0.9637633711099625
1.0013164281845093
0.981984332203865
0.9920093566179276
0.9710386246442795
0.9865829348564148
0.9571205526590347
0.9751581847667694
0.9834210723638535
0.9958949536085129
0.9735412448644638
0.9646566808223724
0.9937527775764465
0.9731350541114807
0.9873587638139725
0.9699916690587997
0.9831473976373672
0.9901112020015717
0.9579982608556747
0.982135221362114
0.9664371460676193
0.9546134918928146
0.9718240648508072
Val losses 
0.6544893432603792
0.6534703294693748
0.6618131566923544
0.6468494301676944
0.6630138294043765
0.6475146041568197
0.6628827011179499
0.6828187686697591
0.6528804247473331
0.6464993597558226
0.6758727074506667
0.6621553767442316
0.673218051495905
0.6721162536477863
0.6646054347484965
0.6418556191353203
0.6506523618435357
0.6636196726531611
0.6634261941085436
0.6596624344056005
0.6482176197534765
0.6578347879380938
0.6498727793631716
0.6440920523860402
0.6585806110689667
