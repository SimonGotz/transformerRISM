CONFIGURATION: 
Training time: 511 
lr: 2e-05
wd: 0.01
d_model: 256
n_heads: 4
n_layers: 1
d_ff: 512
batch_size: 2048
dropout: 0.688012808155219
margin: 0.30836373402760725
epsilon: 1e-07
Train losses 
0.6472320407629013
0.6629573702812195
0.6868663728237152
0.6622854173183441
0.6836467385292053
0.6672795414924622
0.6441362202167511
0.6498432010412216
0.659184530377388
0.6523670107126236
0.6768102645874023
0.659547969698906
0.6617566347122192
0.6658298075199127
0.6614830493927002
0.6578716188669205
0.6517308056354523
0.6568371206521988
0.6540025174617767
0.6641187965869904
0.6500992625951767
0.6637025475502014
0.653410866856575
0.6484928280115128
0.6567960232496262
Val losses 
0.3297496134367973
0.35071032527715434
0.33776509240148905
0.3376088423190537
0.31419457956496477
0.33920570092224417
0.3501090207401319
0.34463242309792885
0.3608663804720441
0.3283354760761972
0.3307147773132654
0.34462376815573326
0.33048126698828334
0.32100582122802734
0.34408286479535716
0.31688426752981785
0.3476889564951068
0.29876239411834765
0.31914842225357626
0.34077664467529756
0.3328569379772514
0.3324970506063221
0.33797744439783
0.3423683824956514
0.3214466166071219
