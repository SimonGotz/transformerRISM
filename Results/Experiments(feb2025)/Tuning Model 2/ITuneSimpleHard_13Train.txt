CONFIGURATION: 
Training time: 884 
lr: 0.001
wd: 0.005
d_model: 256
n_heads: 4
n_layers: 4
d_ff: 128
batch_size: 2048
dropout: 0.02441828654762146
margin: 0.3972009684171713
epsilon: 1e-06
Train losses 
0.5758165121078491
0.5138299390673637
0.443063922226429
0.4014601334929466
0.3984474316239357
0.40095504373311996
0.40396643429994583
0.3874891474843025
0.384492889046669
0.3916584774851799
0.3797519728541374
0.3723108544945717
0.3712734952569008
0.37858346104621887
0.37052223831415176
0.3759847953915596
0.35748840123414993
0.3687596619129181
0.3555138036608696
0.36454465985298157
0.35880229622125626
0.36213385313749313
0.36445489525794983
0.3601245880126953
0.362741194665432
Val losses 
0.3663302918242996
0.3548755346923696
0.2921796597254592
0.2809073936610786
0.2941087823439649
0.2937276168876825
0.29658532905810464
0.29390453857579535
0.2859282534808999
0.29122786010554647
0.28217789657949305
0.28703466696973623
0.29875379359638415
0.286007005546236
0.29567856076342036
0.2986537998653888
0.28903923692862965
0.2875484453543401
0.2988080607434339
0.2830521482702592
0.31416096821274386
0.2852603032227016
0.2935214561104839
0.2846300362381402
0.29298086272002166
