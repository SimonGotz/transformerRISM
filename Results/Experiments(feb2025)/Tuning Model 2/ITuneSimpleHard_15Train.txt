CONFIGURATION: 
lr: 0.002
wd: 0.001
d_model: 128
n_heads: 4
n_layers: 2
d_ff: 1024
batch_size: 64
dropout: 0.5177334160189718
margin: 0.3539006829485196
epsilon: 0.01
Train losses 
0.6447433595304136
0.6519783470365736
0.6243864679778064
0.6143821603722043
0.579116474699091
0.5503248066813857
0.5430552403132121
0.5268654807850167
0.546554066295977
0.5337349401579963
0.530534150644585
0.5173757235209148
0.5130233331962868
0.495453413327535
0.5104943048070978
0.4974747946968785
0.49551116912453264
0.4880641261736552
0.4870051094779262
0.4840293217588354
0.4922107687702885
0.49903761325059115
0.4961441962807267
0.49182625611623126
0.4927131591019807
Val losses 
0.3746801455106054
0.3354633237634386
0.3306789978274277
0.3593165347618716
0.32615923775093897
0.29359590634703636
0.27718496695160866
0.294124678841659
0.26981195168835775
0.2815441372139113
0.2609309341226305
0.25503070492829594
0.2652285620570183
0.26546939302768024
0.25987282608236584
0.268249694790159
0.27634835296443533
0.26236744065369877
0.2679259649344853
0.26548819350344793
0.258093642869166
0.27115131967834066
0.26809698928679737
0.2669177438531603
0.26969863421150614
