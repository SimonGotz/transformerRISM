CONFIGURATION: 
Training time: 175 
lr: 0.001
wd: 0.05
d_model: 32
n_heads: 8
n_layers: 1
d_ff: 1024
batch_size: 2048
dropout: 0.3864209135435105
margin: 0.405155239661079
epsilon: 1e-05
Train losses 
0.6887404173612595
0.6405229717493057
0.5922860503196716
0.5520231872797012
0.5416940152645111
0.5349604487419128
0.5444091856479645
0.5182876586914062
0.5059640109539032
0.5107420682907104
0.5141021758317947
Val losses 
0.35986877479532614
0.3389083483874766
0.31403293511727126
0.30546040315360135
0.3179401015668608
0.3069259482966701
0.31675406303488196
0.3084284441011265
0.3149197874102703
0.3166333832720175
0.32088805273827314
