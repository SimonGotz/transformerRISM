CONFIGURATION: 
Training time: 1122 
lr: 1e-05
wd: 0.0001
d_model: 64
n_heads: 8
n_layers: 2
d_ff: 2048
batch_size: 2048
dropout: 0.1388347391363629
margin: 0.8789406643041591
epsilon: 0.0001
Train losses 
0.9624976366758347
0.9457361251115799
0.94252710044384
0.9643856734037399
0.9713617116212845
0.9387021064758301
0.9451535046100616
0.9528689831495285
0.9438459128141403
0.9535144120454788
0.9726703017950058
0.9590325206518173
0.9497717022895813
0.933955043554306
0.9496373385190964
0.9436308592557907
0.9415370672941208
0.9518682211637497
0.9420163631439209
0.9382925182580948
0.9377690106630325
0.9198331087827682
0.9464338272809982
0.9315235763788223
0.9543341100215912
Val losses 
0.6406039430411167
0.6020939786778083
0.6310012216892582
0.6310846125480615
0.6728461538373555
0.6125448703250648
0.6422926667314939
0.6375545535713579
0.6282739398416347
0.6550830786193402
0.654060737562463
0.6377279749436999
0.6259802593404316
0.6393086200530692
0.6119363385236051
0.6386699749932683
0.6307425763013232
0.6412449454952098
0.6631061534891897
0.6075287211720587
0.6335639459000993
0.6329680988429238
0.6147506789604694
0.6556213258859727
0.6188810875066739
