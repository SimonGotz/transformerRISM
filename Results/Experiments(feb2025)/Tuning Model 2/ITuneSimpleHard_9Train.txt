CONFIGURATION: 
Training time: 554 
lr: 1e-05
wd: 0.01
d_model: 64
n_heads: 16
n_layers: 2
d_ff: 1024
batch_size: 2048
dropout: 0.7509603500112443
margin: 0.1851115219518833
epsilon: 1e-06
Train losses 
0.5568019449710846
0.5562520325183868
0.5594421923160553
0.5644875764846802
0.5537103414535522
0.5575146079063416
0.5475618690252304
0.568994402885437
0.5489374548196793
0.542185589671135
0.5386183559894562
0.5650646686553955
0.5468776375055313
0.5552426427602768
0.5494513213634491
0.5501553565263748
0.5423037260770798
0.5553000122308731
0.5583491623401642
0.5439997762441635
0.5369103401899338
0.5429270267486572
0.5482528954744339
0.540895864367485
0.5523610860109329
Val losses 
0.286453735886362
0.2952640458482591
0.3029668286064391
0.28122272586770986
0.2958043093039885
0.27721186704341944
0.27244745248849167
0.2779605214754225
0.27566238959243916
0.25687194256960283
0.25675903920029897
0.26631887367388674
0.29069058332231995
0.28464566199345437
0.2936632430984934
0.2744338822841387
0.2760185990573135
0.29004671057129733
0.28721057486366675
0.28672545385128867
0.298646910135196
0.28284809989970416
0.2746581960407094
0.28516120758654295
0.2879082631060138
