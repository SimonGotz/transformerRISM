CONFIGURATION: 
lr: 0.0002
wd: 0.05
d_model: 512
n_heads: 16
n_layers: 1
d_ff: 512
batch_size: 128
dropout: 0.6044735692360708
margin: 0.7240989159575346
epsilon: 1e-06
Train losses 
0.9051775683217974
0.9090406832410328
0.8890939434962486
0.8673680406897816
0.8639068203185921
0.8154807517777628
0.872181487617208
0.8511767467456077
0.8473660207506436
0.8490113357999431
0.8528738573415956
0.8250056798778364
0.8325148945424095
0.8192905810341906
0.8357190338533316
0.819835497372186
0.8266250846990898
0.8204803324457425
0.814149595018643
0.8163078009192624
0.8155654633223121
0.804370635481023
0.820886994475749
0.8155937862040391
0.8024042391065341
Val losses 
0.5065354491983142
0.5165980607271194
0.49548445854868206
0.5458815544843674
0.5060248779399055
0.5247898484979358
0.5031329542398453
0.48934301308223177
0.48125908204487394
0.4812477443899427
0.4801944707121168
0.48375637190682547
0.4717339106968471
0.48657347687653135
0.5185788720846176
0.49159305010523113
0.49832605038370403
0.5011587419680187
0.486613039459501
0.4885852656194142
0.5013588305030551
0.4896582067012787
0.4853366379226957
0.4913357985871179
0.48801225210939136
