CONFIGURATION: 
Training time: 396 
lr: 0.0001
wd: 0.001
d_model: 16
n_heads: 16
n_layers: 1
d_ff: 256
batch_size: 2048
dropout: 0.6294645278134767
margin: 0.5511881442315418
epsilon: 1e-08
Train losses 
0.8403236418962479
0.8289714604616165
0.8600258529186249
0.8618166446685791
0.8395373076200485
0.8513399958610535
0.8183130025863647
0.8433665782213211
0.8254012912511826
0.825896680355072
0.8267689049243927
0.8324138224124908
0.8031192272901535
0.8094946444034576
0.805988073348999
0.8166592717170715
0.8226690590381622
0.8227381855249405
0.7916354984045029
0.8191980719566345
0.8140612542629242
0.8282447904348373
0.8229118436574936
0.8170368671417236
0.817890927195549
Val losses 
0.4504253082118248
0.45643410891664793
0.4472018732437245
0.4435781194898388
0.4528761498996337
0.457598393878571
0.44156863440184385
0.4500863316701851
0.4544518117902087
0.4484488743823776
0.44278013794760906
0.4493540943409545
0.4503613628451081
0.4425169633312009
0.46543580773455073
0.4574081032003086
0.46066498308810333
0.4519643949245131
0.438296888452295
0.44174145872949716
0.4542385852059952
0.4323290636383605
0.4579505577305083
0.4569273298653572
0.43643090877579327
