CONFIGURATION: 
Training time: 836 
lr: 0.001
wd: 0.0001
d_model: 128
n_heads: 16
n_layers: 4
d_ff: 256
batch_size: 2048
dropout: 0.7724183288791959
margin: 0.37456179304131126
epsilon: 1e-05
Train losses 
0.6306118965148926
0.6381531655788422
0.6509623676538467
0.639192521572113
0.6253767162561417
0.6049445569515228
0.6053837388753891
0.5967633426189423
0.6118665635585785
0.5931435972452164
0.602717325091362
0.5892823189496994
0.5807029157876968
0.5745963603258133
0.5717903077602386
0.5509651005268097
0.5748482346534729
0.5740181356668472
0.558774396777153
0.5631801933050156
0.5416100472211838
0.5492238849401474
0.5623499155044556
0.5366571396589279
0.5597197562456131
Val losses 
0.3367801127338461
0.3458290262392313
0.3605218590561729
0.3567235396399104
0.3151133453311436
0.31268824956534297
0.3037871320076339
0.28401111229763104
0.29143736234940043
0.26795792064429746
0.26773092219921013
0.26575984045468687
0.25335046267393535
0.271489885998442
0.26353536587287
0.2569379352479932
0.2608408054617661
0.26361534577456763
0.2612284418056618
0.25863655839721167
0.26885623593126873
0.2646825965322848
0.25555925128396817
0.26503622261399773
0.2603736433836011
