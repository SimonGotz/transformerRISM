CONFIGURATION: 
lr: 2e-06
wd: 0.1
d_model: 512
n_heads: 4
n_layers: 2
d_ff: 512
batch_size: 32
dropout: 0.5057461022052275
margin: 0.5096955522808617
epsilon: 1e-06
Train losses 
0.7309256306401005
0.7445877152460593
0.7236523749651732
0.738094280163447
0.7362360740149463
0.7655034091737535
0.7784875039701109
0.7546427927635334
0.7614951177879616
0.7732112809463784
0.7811130130732501
0.7605853369942418
0.753971090360924
0.7544972375587181
0.7635889543427361
0.7643643522704089
0.7501775988826045
0.7677960673967997
Val losses 
0.4179447606990212
0.42860216372891474
0.4486316886910221
0.4409900788675275
0.4445507678023556
0.4461449813424495
0.4216291684853403
0.4372631619896805
0.417209549954063
0.44812190689538656
0.44089798132578534
0.4639707605044047
0.4590225460236533
0.4697015803111227
0.4278359073295928
0.44594491103239225
0.4513711375102662
0.45187093343651086
