CONFIGURATION: 
lr: 2e-06
wd: 0.0001
d_model: 16
n_heads: 2
n_layers: 2
d_ff: 1024
batch_size: 256
dropout: 0.49320954948535434
margin: 0.6819095888620433
epsilon: 0.1
Train losses 
0.8803648388747013
0.8816199483293475
0.8646429289471019
0.8642551591902068
0.8737697222016074
0.8689978754881656
0.8735720713933309
0.87966172803532
0.890852538022128
0.8706098108580618
0.8644670537023833
0.8712354717832623
0.8941949533693718
0.8784324490662777
0.8897927656318202
0.8548272017276648
0.8968242768085364
0.8917650742964311
0.8796664115154382
0.8669948559818845
0.886181784398628
0.8615042549191099
Val losses 
0.40978492157799856
0.4122669739382608
0.44090893864631653
0.4324746642793928
0.4134146400860378
0.436135538986751
0.4547668397426605
0.4166914565222604
0.4268904115472521
0.4142594635486603
0.41875178047588896
0.3955442862851279
0.43812223417418344
0.4300260373524257
0.40828279086521696
0.42388842361313955
0.4424351836953844
0.42070609756878447
0.39900737575122286
0.4079395404883793
0.4235805230481284
0.4328454179423196
