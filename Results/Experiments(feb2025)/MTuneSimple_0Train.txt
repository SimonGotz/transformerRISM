CONFIGURATION: 
Training time: 686 
lr: 0.0001
wd: 0.05
d_model: 1024
n_heads: 2
n_layers: 2
d_ff: 128
batch_size: 32
dropout: 0.012698936287112605
margin: 0.2459901280907921
epsilon: 1e-07
Train losses 
0.5356925236406149
0.28197303695811166
0.15684273085660405
0.12105829707450337
0.09856089061057126
0.0832617125025502
0.07951904838835752
0.06540277089785647
Val losses 
0.4720422327518463
0.23519662022590637
0.1591973900794983
0.1836715042591095
0.17193125188350677
0.12376468628644943
0.12915728986263275
0.14091254770755768
