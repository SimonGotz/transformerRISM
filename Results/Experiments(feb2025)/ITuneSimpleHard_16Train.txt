CONFIGURATION: 
lr: 2e-05
wd: 0.005
d_model: 256
n_heads: 4
n_layers: 1
d_ff: 2048
batch_size: 1024
dropout: 0.35210193093593
margin: 0.26616913185950486
epsilon: 0.001
Train losses 
0.571541078388691
0.5692007392644882
0.569524884223938
0.5670961514115334
0.5713345110416412
0.6337358504533768
0.6254774481058121
0.6448747739195824
0.6468836590647697
0.640995167195797
0.6386403292417526
0.6344485953450203
0.643359012901783
0.6352669224143028
0.6471032053232193
0.6295521780848503
0.6458588987588882
0.6284772530198097
0.6237439066171646
0.6364821195602417
0.6240366473793983
0.6414903253316879
0.6257278248667717
0.643021747469902
0.6259624809026718
Val losses 
0.3256385922431946
0.3386438190937042
0.33250296115875244
0.3235434889793396
0.3601531982421875
0.36178410053253174
0.3089306354522705
0.3375434875488281
0.30804404616355896
0.3409098982810974
0.3180159628391266
0.3392004668712616
0.3344374895095825
0.32908985018730164
0.33377358317375183
0.32026195526123047
0.31850770115852356
0.29784369468688965
0.36387699842453003
0.30176693201065063
0.33037516474723816
0.32534438371658325
0.34997907280921936
0.3431795537471771
0.32471224665641785
