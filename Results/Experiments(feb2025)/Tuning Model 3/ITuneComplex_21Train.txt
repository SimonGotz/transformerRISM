CONFIGURATION: 
lr: 1e-05
wd: 0.0005
d_model: 128
n_heads: 2
n_layers: 1
d_ff: 1024
batch_size: 128
dropout: 0.34795568470353955
margin: 0.6303532946412017
epsilon: 1e-07
Train losses 
0.7666510201212186
0.7789981338515211
0.7681216517491127
0.7659726605486514
0.7453567296711366
0.7492852575743376
0.7507536927265908
0.7471618011816225
0.7517902886689599
0.745091632230958
0.7476034689305434
0.729861347532984
0.7345411599572025
0.7361415108638023
0.7273775419192527
0.7410554254232947
0.7385974855565313
0.7366194244640977
Val losses 
0.5152365842035839
0.5260266235896519
0.510365007179124
0.5114747434854507
0.4668412378856114
0.4419819435903004
0.4641997792891094
0.4319961965084076
0.433583670428821
0.47299404442310333
0.45028847455978394
0.4624109502349581
0.4723266363143921
0.45675499737262726
0.4394502767494747
0.44813645098890575
0.44890459520476206
0.46208182190145763
