CONFIGURATION: 
lr: 0.0001
wd: 0.0001
d_model: 1024
n_heads: 2
n_layers: 3
d_ff: 2048
batch_size: 128
dropout: 0.6744741434864476
margin: 0.11570748093904125
epsilon: 1e-05
Train losses 
0.46388017197153464
0.45751126533123987
0.45022548890825526
0.4234647212633446
0.41595079471815877
0.403530031887453
0.39002611788351144
0.3637524407301376
0.34056845129425845
Val losses 
0.3630715597953115
0.3675597033330372
0.3720362846340452
0.40140730142593384
0.5016229450702667
0.4615726109061922
0.6717392270054136
0.7405117579868862
0.9910335327897754
