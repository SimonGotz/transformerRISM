CONFIGURATION: 
lr: 0.001
wd: 0.1
d_model: 1024
n_heads: 16
n_layers: 2
d_ff: 256
batch_size: 128
dropout: 0.2641384885090866
margin: 0.7717265925324803
epsilon: 0.001
Train losses 
0.5994751364437502
0.5691393458131534
0.5039962387796658
0.4568361800108383
0.4515606765426807
0.4551022911249702
0.4278658535053481
0.39493680756483507
0.3893812111954191
0.3717234659550795
0.3767462486206596
0.368068124820937
0.36612670190298735
0.3523969946067725
0.34378792834815697
0.3568341909949459
0.3464671021966792
0.3320275111429727
0.3407390578024423
0.3383196409958512
0.33256456745204643
0.3322230321702673
0.33855595739919747
0.3325362579146428
0.32712618650785136
Val losses 
0.4620529647384371
0.5222551950386592
0.46551758689539774
0.48442902309553965
0.47085716681821005
0.48681105247565676
0.48806246902261463
0.48720282529081615
0.4026305909667696
0.43753765310559956
0.4335082301071712
0.388629396046911
0.37857783479349955
0.4335771862949644
0.37905709019729067
0.37699539746556965
0.3654668139559882
0.43826226783650263
0.36567688626902445
0.38727158520902905
0.3740840469087873
0.38395084760018755
0.4008182553308351
0.36498942758355823
0.3855140932968685
