CONFIGURATION: 
lr: 1e-05
wd: 0.05
d_model: 64
n_heads: 8
n_layers: 2
d_ff: 2048
batch_size: 32
dropout: 0.4265937788152583
margin: 0.31333624579332087
epsilon: 1e-07
Train losses 
0.6017255201935768
0.5799442215098275
0.5584866907861498
0.5278320938348771
0.5105647846504494
0.4871838630901443
0.4614425606749676
0.45577431111424055
0.4545527042614089
0.44095445347053036
0.4456663080387645
0.43813498202297424
0.4286489087122458
0.43264590744619014
0.42695442106988696
0.435575683746073
0.4219787127993725
0.42807036196744
0.4246251627250954
0.4200608066386647
0.42498381314454253
0.4240684722860654
0.4291353836655617
0.42294507633756706
0.42116631065253857
Val losses 
0.23778751727781797
0.23866353092486398
0.22011512243434003
0.2185162227404745
0.21249625361279437
0.2125978609710409
0.17424564821678296
0.17672462532656236
0.18146403918140813
0.16894693162880445
0.18237705071244323
0.16510663678248724
0.15850228986196352
0.15533610649014773
0.17281869916539444
0.16262729426747874
0.163572219903009
0.16899485598530686
0.1556883732739248
0.157321729877016
0.16527425210204041
0.15970411073220403
0.1683294307767299
0.16612662531827627
0.16245691439038829
