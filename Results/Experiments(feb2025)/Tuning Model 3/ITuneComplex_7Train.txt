CONFIGURATION: 
lr: 0.0002
wd: 0.0005
d_model: 32
n_heads: 8
n_layers: 3
d_ff: 256
batch_size: 256
dropout: 0.5310990241851034
margin: 0.4845426698807686
epsilon: 0.1
Train losses 
0.7030838691827023
0.689192553361257
0.6972097898974563
0.6842145504373492
0.692980372544491
0.6916277408599854
0.688473667159225
0.6870778401692709
0.6965684547568812
0.6987733660322247
0.6825238231456641
0.6794740467360525
0.7023262309305596
0.6902798071052089
0.7000842419537631
0.6777125885992339
0.670142796906558
0.6807019475734595
0.6895574439655651
0.7063934261148627
0.692977867343209
0.6958001472733237
0.6956514625838308
0.6965997815132141
0.6762452685471737
Val losses 
0.34732131021363394
0.34416578497205463
0.3589786503996168
0.35681005886622835
0.33222445845603943
0.3476180391652243
0.33405056595802307
0.3477001360484532
0.3277808555534908
0.33638266154697966
0.35365488273756845
0.3447950482368469
0.34329141889299664
0.36534727045467924
0.340824442250388
0.3476253662790571
0.35001172763960703
0.34210646578243803
0.34021569575582233
0.36654206684657503
0.3511826864310673
0.33761936000415255
0.33156403473445345
0.3174606263637543
0.337477513722011
