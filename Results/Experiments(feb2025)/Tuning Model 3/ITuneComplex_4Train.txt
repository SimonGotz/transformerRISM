CONFIGURATION: 
lr: 1e-05
wd: 0.05
d_model: 16
n_heads: 4
n_layers: 1
d_ff: 2048
batch_size: 128
dropout: 0.631861425936829
margin: 0.8252090929965554
epsilon: 1e-07
Train losses 
0.9910643545549307
0.9700977677729592
0.9807947767314626
0.9607065257741444
0.9727040289053276
0.9457172021937015
0.9434688758494248
0.9496152294215872
0.9406331065875381
0.9308445738322699
0.9445490534625837
0.9580759904277858
0.9496545960654074
0.9494163269427285
0.9330620454318488
0.9394448782081035
0.9331257058613336
0.9351527584132864
0.9134676554309789
0.9345883718177453
0.9172450428578391
0.9401660312467547
0.9373605233519825
0.9325330221830909
0.9358976679061776
Val losses 
0.5392682360751289
0.5464678278991154
0.5191988476685115
0.5385633685759136
0.5369562315089362
0.5403833091259003
0.523944731269564
0.5505763675485339
0.5365016311407089
0.5213830066578728
0.5246520021132061
0.5140312782355717
0.5438463773046222
0.537656443459647
0.5297542299543109
0.5502030019249234
0.5167593955993652
0.5613189488649368
0.5525114919458117
0.5540582601513181
0.5350082069635391
0.5395058116742543
0.5234745634453637
0.5435697031872613
0.5502020631517682
