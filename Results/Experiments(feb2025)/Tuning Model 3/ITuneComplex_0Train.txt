CONFIGURATION: 
lr: 2e-06
wd: 0.1
d_model: 16
n_heads: 4
n_layers: 2
d_ff: 256
batch_size: 512
dropout: 0.39452751804838804
margin: 0.630187536593566
epsilon: 0.0001
Train losses 
0.7704960778355598
0.7732329182326794
0.7749363631010056
0.7718633338809013
0.7747169733047485
0.7410214506089687
0.767705861479044
0.7669361084699631
0.7920551598072052
0.7650086171925068
0.747346505522728
0.766901783645153
0.7807428054511547
0.7603899352252483
0.7672841809689999
0.7823707051575184
0.7857527323067188
0.7592443265020847
0.7780828401446342
0.7601895444095135
0.7572518885135651
0.7676945738494396
0.7607135735452175
0.7792389504611492
0.7728942446410656
Val losses 
0.4279737174510956
0.3909643292427063
0.4001791675885518
0.4296781023343404
0.40953967968622845
0.392427255709966
0.4055188298225403
0.41921087106068927
0.40022096037864685
0.4036502540111542
0.4186867872873942
0.40151212612787884
0.4298727214336395
0.3852890531222026
0.4144983192284902
0.4285123248895009
0.4116908510526021
0.41954754789670307
0.41756781935691833
0.437582661708196
0.4294792016347249
0.4082983632882436
0.4345677097638448
0.38801323374112445
0.4177379906177521
