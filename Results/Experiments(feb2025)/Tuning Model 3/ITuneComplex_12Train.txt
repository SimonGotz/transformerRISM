CONFIGURATION: 
lr: 1e-05
wd: 0.05
d_model: 128
n_heads: 4
n_layers: 3
d_ff: 256
batch_size: 128
dropout: 0.57938226211107
margin: 0.9382317686031046
epsilon: 0.01
Train losses 
1.0325847454925081
1.0274123407121916
1.026555061340332
1.035852131558888
1.009873930198043
1.019153880539225
1.0283038785208518
1.0313802646167243
1.0167988707770164
1.015315047840574
1.008503761754107
1.0026524574009341
1.004075427553547
1.014281628736809
1.001609826265876
1.0318125290657156
1.0289751113350711
1.0404946981970944
1.0327875961118669
1.003365530006921
1.0232536721585401
1.0102678332755815
1.0060562082191011
1.0132538729639196
1.0165733561586978
Val losses 
0.530377100620951
0.5358911156654358
0.526781793151583
0.5461881714207786
0.5222468972206116
0.5260855853557587
0.5067173604454313
0.5332195652382714
0.4990892005818231
0.4836894529206412
0.5045114989791598
0.5331714898347855
0.5328322244541985
0.5280750053269523
0.526208181466375
0.53375315453325
0.5324784006391253
0.5289338103362492
0.5044905458177839
0.4996250867843628
0.5586395753281457
0.5255788202796664
0.5484574926751
0.54571590253285
0.5080440725599017
