CONFIGURATION: 
lr: 2e-06
wd: 0.01
d_model: 128
n_heads: 16
n_layers: 1
d_ff: 128
batch_size: 64
dropout: 0.35349726857331265
margin: 0.13527575067186282
epsilon: 1e-07
Train losses 
0.46050421330663893
0.46624237254813866
0.4625695080668838
0.46579947626149215
0.45727409256829155
0.4640085112165522
0.45388632350497776
0.459027314958749
0.45484931468963624
0.4515147105411247
0.4508564414801421
0.4644015098059619
0.4572388216301247
0.44446701032144054
0.4477216686363573
0.44007505068072567
0.4429398229828587
0.44343094141395006
0.453727157579528
0.44921602805455524
0.4500129211831976
0.4504288313565431
0.46031463499422426
0.44939405377264374
Val losses 
0.1956280448607036
0.20036002221916402
0.17324060494346277
0.20385094013597285
0.20329828480524675
0.1922720582889659
0.18784346617758274
0.18664326279291085
0.17889283996607577
0.186175974085927
0.19536463410726615
0.1946976219436952
0.18049168506903307
0.1887753467474665
0.18023358870829856
0.2037292452795165
0.19939380963998182
0.19201187177428178
0.1917635646781751
0.19393931355859553
0.19111040819968497
0.1923944660063301
0.19496696309319564
0.19586191007069179
