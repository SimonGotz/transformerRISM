CONFIGURATION: 
lr: 2e-06
wd: 0.0001
d_model: 64
n_heads: 8
n_layers: 2
d_ff: 128
batch_size: 64
dropout: 0.6272962710851858
margin: 0.8816116168372511
epsilon: 0.0001
Train losses 
1.0336881302021168
1.0109765074871204
1.001443906183596
1.0287265472941929
1.0097809124875952
1.0048798547850715
1.0198925146350155
1.0323120995804116
1.0539355869646425
1.0401522053612604
1.0188110086652968
1.007197164606165
1.031327701056445
1.0371159897910225
1.044339359248126
1.0291826667609039
1.0198868340916103
Val losses 
0.6770936612571988
0.6521885395050049
0.6524560419576508
0.6754548443215234
0.6523486695119313
0.697218235049929
0.6877846057925906
0.6653638673680169
0.6488019760165896
0.6708315738609859
0.6763971682105746
0.6346226366502898
0.6721485193286624
0.6666561556713921
0.6678831364427295
0.6679275291306632
0.6810268461704254
