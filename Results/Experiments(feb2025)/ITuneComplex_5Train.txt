CONFIGURATION: 
lr: 2e-06
wd: 0.005
d_model: 1024
n_heads: 8
n_layers: 4
d_ff: 128
batch_size: 256
dropout: 0.7310683984164851
margin: 0.6673911711895757
epsilon: 1e-08
Train losses 
0.8030663042357473
0.7954943938688799
0.7843509677684668
0.8037061980276397
0.7980496377655955
0.8050374804121075
0.8067259029908613
0.7871130452011571
0.8074881849866925
0.7900372635234486
Val losses 
0.433553478547505
0.4573203665869577
0.4295001881463187
0.45560117278780254
0.42457745330674307
0.3805015981197357
0.3759738164288657
0.3917195626667568
0.4136922061443329
0.4225480854511261
