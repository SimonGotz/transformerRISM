CONFIGURATION: 
lr: 2e-06
wd: 0.1
d_model: 1024
n_heads: 4
n_layers: 2
d_ff: 1024
batch_size: 16
dropout: 0.018752679460003654
margin: 0.32411045675241346
epsilon: 0.1
Train losses 
0.4364455191073594
0.44588302429075594
0.4327127629960025
0.44488480974126743
0.4405743685033586
0.44528584270565597
0.4437648168316594
0.4376088692082299
0.44442434189496216
0.4468898312913047
0.44555725322829354
0.4537911191030785
0.45044234306723985
0.4429622358745999
0.448883169999829
0.4465855081876119
0.4370611686397482
0.4435283361761658
0.4437352847169947
0.44242485971362505
0.4358759346935484
0.4366181053497173
0.4465914718530796
0.43944993394392506
0.441515702340338
Val losses 
0.48928093547406404
0.5273721959279931
0.5188750712767891
0.4857042794642241
0.508079935675082
0.5367498003918192
0.4931536529375159
0.5060159449991972
0.531417079075523
0.5172361228777015
0.5532564831816632
0.5364701701247174
0.4740866925405419
0.5213418970937315
0.47929180653198905
0.5046764570733775
0.49954379848811936
0.5163524099018263
0.505406085304592
0.4903459756270699
0.5267261862754822
0.5269471883773804
0.5068649074305659
0.49173615237940915
0.5108001683069312
