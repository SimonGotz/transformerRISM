CONFIGURATION: 
lr: 2e-05
wd: 0.0005
d_model: 32
n_heads: 4
n_layers: 3
d_ff: 512
batch_size: 1024
dropout: 0.4189024066193214
margin: 0.6311334468090597
epsilon: 1e-05
Train losses 
0.822880208492279
0.8129664286971092
0.8145558759570122
0.8160212188959122
0.8061205521225929
0.8034095615148544
0.7909236401319504
0.794673964381218
0.7885063886642456
0.7691676914691925
0.7846205681562424
0.7773063257336617
0.7698493152856827
0.7738749384880066
0.7703473046422005
0.770388126373291
0.7749509066343307
0.7583318278193474
0.7548811063170433
0.7737666144967079
0.7548190057277679
0.7540970668196678
0.7618831172585487
0.7503902986645699
0.7471482083201408
Val losses 
0.5271311402320862
0.5299593210220337
0.5504388213157654
0.5198566317558289
0.4920702278614044
0.5251620411872864
0.5060564279556274
0.511508584022522
0.5026888847351074
0.524925947189331
0.4968986511230469
0.4888759255409241
0.49474239349365234
0.5197292566299438
0.4921523928642273
0.49406248331069946
0.5066322088241577
0.4946134388446808
0.4889048933982849
0.5034874081611633
0.4986332058906555
0.5083277225494385
0.5031799077987671
0.46460461616516113
0.5010647177696228
