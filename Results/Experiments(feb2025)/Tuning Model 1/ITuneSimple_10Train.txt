CONFIGURATION: 
lr: 1e-06
wd: 0.05
d_model: 256
n_heads: 2
n_layers: 1
d_ff: 2048
batch_size: 32
dropout: 0.7168349845867351
margin: 0.36402669955692535
epsilon: 1e-07
Train losses 
0.6540584327997985
0.6503911667399936
0.6672978140689708
0.6498808640020864
0.6702952203927217
0.6594566111211424
0.6537223829163445
0.6561592737833659
0.6703579196223506
0.6728585009221677
0.650034734054848
0.6689352865572329
0.6528353379832373
0.6590351793501112
0.6582330917870557
0.6732686769079279
0.6587044499538562
0.6437775278532947
0.6651035028475302
0.6534238446641851
0.6535833440445088
0.6469362404611375
0.6453524766144929
Val losses 
0.40649196583973735
0.3972200006246567
0.4362121266231202
0.4477719494648147
0.42643602375398604
0.44705279877311305
0.4614858922728321
0.4375840331378736
0.4396068809325235
0.4359548559837174
0.4248025218645732
0.4105741227405113
0.4059461906813739
0.43041490358218815
0.4578320776161395
0.4483259822192945
0.42552334096348077
0.43579103287897614
0.47107275954464023
0.42104180392466095
0.4267015028418156
0.4286840087489078
0.433696348154754
