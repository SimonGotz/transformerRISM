CONFIGURATION: 
lr: 1e-06
wd: 0.005
d_model: 16
n_heads: 16
n_layers: 3
d_ff: 2048
batch_size: 1024
dropout: 0.5200674705287688
margin: 0.8022399666546659
epsilon: 1e-05
Train losses 
0.9452551826834679
0.9378050044178963
0.9378712177276611
0.9666372835636139
0.9577468559145927
0.9527116492390633
0.9583611264824867
0.9387597143650055
0.93865005671978
0.9566979110240936
0.9598781242966652
0.966748021543026
0.9462279677391052
0.939904972910881
0.9686134830117226
0.9537875950336456
0.9411177113652229
0.9475801885128021
0.9590153768658638
0.9533815085887909
0.9359320923686028
0.947224423289299
0.9370550513267517
0.9638758972287178
0.954463467001915
Val losses 
0.6738475561141968
0.6514797806739807
0.6298865675926208
0.6586753726005554
0.643098771572113
0.6462125778198242
0.6296675205230713
0.6097135543823242
0.6339291334152222
0.6051136255264282
0.666887104511261
0.6314125657081604
0.6687090992927551
0.6780937910079956
0.6449403762817383
0.6232333779335022
0.624170184135437
0.6587857604026794
0.6448871493339539
0.6226269006729126
0.6394599676132202
0.6509677171707153
0.634623110294342
0.6768779754638672
0.638144850730896
