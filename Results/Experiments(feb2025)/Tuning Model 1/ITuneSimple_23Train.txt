CONFIGURATION: 
lr: 1e-05
wd: 0.01
d_model: 32
n_heads: 16
n_layers: 4
d_ff: 512
batch_size: 1024
dropout: 0.368645454001985
margin: 0.2309613011731985
epsilon: 1e-05
Train losses 
0.5537017956376076
0.5691070035099983
0.5436132475733757
0.5412324443459511
0.5214089043438435
0.5189605057239532
0.5296080708503723
0.5266982987523079
0.5187786631286144
0.5174396336078644
0.5240682512521744
0.505405355244875
Val losses 
0.3377271294593811
0.3561962842941284
0.3117844760417938
0.340687096118927
0.33010178804397583
0.3528541028499603
0.3406498432159424
0.3212704062461853
0.30330151319503784
0.3037928342819214
0.3206234276294708
0.3256896138191223
