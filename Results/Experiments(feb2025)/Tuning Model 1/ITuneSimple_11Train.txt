CONFIGURATION: 
lr: 0.0001
wd: 0.001
d_model: 256
n_heads: 4
n_layers: 2
d_ff: 256
batch_size: 64
dropout: 0.5335608682321682
margin: 0.35885381198726424
epsilon: 0.01
Train losses 
0.6652803621910236
0.662827941664943
0.6720860134672235
0.6735433556415417
0.6657325157412777
0.6512030822259408
0.6679944881686458
0.6676501490451672
0.6533459740656393
0.6647313623516647
0.6726875556839838
0.6631425208515591
0.6587657705501274
0.6624867600423319
0.6657465559464913
0.6656036376953125
0.6595359327616515
0.6650945361013766
0.6682663319287476
Val losses 
0.3243296928703785
0.31775512439864023
0.3286255257470267
0.3255591887448515
0.32871315787945476
0.3459815766130175
0.328159861266613
0.3256663350122316
0.3455304971763066
0.3452629681144442
0.3392864337989262
0.34024913502591
0.3492175723825182
0.32571300332035336
0.3403596319258213
0.3374809761132513
0.3423483722976276
0.3438889698258468
0.35519866911428316
