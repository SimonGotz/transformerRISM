CONFIGURATION: 
lr: 0.001
wd: 0.0005
d_model: 32
n_heads: 2
n_layers: 1
d_ff: 512
batch_size: 64
dropout: 0.5943232702544616
margin: 0.3907793933186456
epsilon: 1e-07
Train losses 
0.6761666869675672
0.593310221919307
0.5564963161945343
0.5554533686902788
0.5349660725505264
0.5159417446012851
0.513648576868905
0.5024973827379721
0.4884351432323456
0.4841739590521212
Val losses 
0.3922514553580965
0.3378317185810634
0.33969048517090933
0.33759463897773195
0.31572097327028004
0.3326552041939327
0.32934505279575077
0.3313364971961294
0.3322176603334291
0.33240085414477755
