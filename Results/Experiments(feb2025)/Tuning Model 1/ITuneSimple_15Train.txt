CONFIGURATION: 
lr: 2e-06
wd: 0.05
d_model: 256
n_heads: 2
n_layers: 3
d_ff: 1024
batch_size: 64
dropout: 0.11021661117137516
margin: 0.5585060082556325
epsilon: 1e-07
Train losses 
0.5373544346403193
0.5478214153537044
0.5399082199290947
0.5485361966821882
0.526202216413286
0.5343600632967772
0.5346017047210976
0.5207021057605743
0.539928201172087
0.5212911387284597
0.5101767005743804
0.49773246116108366
0.5133063868240074
0.5188440492859593
0.5109154182451743
0.512313981850942
0.48814290210052774
Val losses 
0.5011497257011277
0.5422889494470188
0.4979898961527007
0.5186972820333072
0.4986614499773298
0.5158577178205762
0.4661911502480507
0.4726328051515988
0.48868176553930553
0.48485774440424784
0.488442953143801
0.4960163193089621
0.4845905953219959
0.4432675412722996
0.4670069430555616
0.4728971613304956
0.47790511697530746
