CONFIGURATION: 
lr: 0.0001
wd: 0.01
d_model: 256
n_heads: 8
n_layers: 4
d_ff: 128
batch_size: 512
dropout: 0.23134761087313171
margin: 0.9209015328273347
epsilon: 1e-07
Train losses 
0.8514783829450607
0.8524992503225803
0.8411307781934738
0.7962442971765995
0.7747066356241703
0.7748845852911472
0.7194543369114399
0.6772112175822258
0.6461845301091671
0.6277204006910324
0.6105657443404198
0.5737673528492451
0.5548794232308865
0.5498196482658386
0.5491295009851456
0.5336844697594643
0.5171186048537493
0.506425105035305
0.49768806248903275
0.49483065120875835
0.4984063506126404
0.49432668648660183
0.48905036225914955
0.48846036940813065
0.5141812767833471
Val losses 
0.6011373003323873
0.6010162432988485
0.5923243562380472
0.5525899728139242
0.5760297377904257
0.5586061080296835
0.49262499809265137
0.5517494082450867
0.5964516202608744
0.5514769554138184
0.6132763822873434
0.5713526606559753
0.5347981850306193
0.5765923659006754
0.5227389931678772
0.5274803837140402
0.5677255988121033
0.5340044498443604
0.5234505633513132
0.5493979851404825
0.52577805519104
0.5302769045035044
0.5206270615259806
0.5454715092976888
0.578336258729299
