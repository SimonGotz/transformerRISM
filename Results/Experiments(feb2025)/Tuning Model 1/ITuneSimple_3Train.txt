CONFIGURATION: 
lr: 1e-05
wd: 0.005
d_model: 1024
n_heads: 16
n_layers: 3
d_ff: 512
batch_size: 1024
dropout: 0.4066971770636867
margin: 0.5250546610877488
epsilon: 1e-06
Train losses 
0.6512290239334106
0.6528990417718887
0.6468326672911644
0.6626920700073242
0.6597101241350174
0.639878936111927
0.6529576182365417
0.6479430720210075
0.6613414138555527
0.6530646830797195
0.638951800763607
0.6313031390309334
0.6409629285335541
0.6326295658946037
0.6495617255568504
0.6182084158062935
0.6409403085708618
0.6325416564941406
0.6278957203030586
0.6425221487879753
0.6303124502301216
0.643338181078434
0.6392101272940636
0.6267143785953522
Val losses 
0.3907943069934845
0.41492369771003723
0.389123797416687
0.39367765188217163
0.3532898426055908
0.3633743226528168
0.4100215435028076
0.3964754045009613
0.38241368532180786
0.36565566062927246
0.3829779624938965
0.3999324440956116
0.36987560987472534
0.36855000257492065
0.3874369263648987
0.3875143229961395
0.3755667805671692
0.40884488821029663
0.3719036877155304
0.3887050449848175
0.37641000747680664
0.3823310136795044
0.3870830833911896
0.387426495552063
