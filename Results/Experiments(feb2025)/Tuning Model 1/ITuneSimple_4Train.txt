CONFIGURATION: 
lr: 0.001
wd: 0.005
d_model: 256
n_heads: 16
n_layers: 4
d_ff: 1024
batch_size: 128
dropout: 0.037526191889284105
margin: 0.9457259592737651
epsilon: 0.0001
Train losses 
0.6025734890752764
0.4983417182715971
0.36639483806802264
0.28724101853014816
0.22886178642511368
0.20379106244489328
0.17392361030649783
0.1658382225614875
0.14191270397225422
0.12448256907623205
0.11232883438690384
0.09649260742450828
0.09824239195727591
0.08943849679694246
0.08665792899790095
0.0813276027120761
0.06982831134280162
0.06875181687411977
0.06511893646040959
0.05454496049614095
0.05690085387496806
0.0501548653440689
0.0496409143974532
0.05075829109149193
0.05202323821053576
Val losses 
0.6085259573800224
0.49856885841914583
0.45791750720569063
0.45405099434512003
0.47006855905056
0.44380159250327517
0.45305653129305157
0.4697490100349699
0.42233128419944216
0.38284256415707724
0.4527052215167454
0.4767038971185684
0.4123113623687199
0.44545928708144594
0.41955057850905825
0.38359400417123524
0.4009511428219931
0.35014589769499643
0.3853485882282257
0.36257520637341906
0.3831587369952883
0.33425956325871603
0.38580902772290365
0.33003175471510204
0.39774044922419954
