CONFIGURATION: 
lr: 0.0001
wd: 0.005
d_model: 32
n_heads: 8
n_layers: 2
d_ff: 128
batch_size: 512
dropout: 0.4643147084932312
margin: 0.38982321500859457
epsilon: 0.0001
Train losses 
0.7160238549113274
0.6985413767397404
0.7060032971203327
0.6724975071847439
0.6608679965138435
0.6536510810256004
0.6481379754841328
0.6264137551188469
0.6299434415996075
0.6221919916570187
0.6170951388776302
0.6155961006879807
0.6191527806222439
0.5936207063496113
0.5960369035601616
0.5890003331005573
0.6037412397563457
0.5823100507259369
0.5866209156811237
0.5714059062302113
0.5913860686123371
0.5777838490903378
0.5980040542781353
0.5833025425672531
0.5803791843354702
Val losses 
0.3636131485303243
0.3666069209575653
0.3491814037164052
0.3423567016919454
0.3652845621109009
0.3408517340819041
0.3464413285255432
0.3494669596354167
0.3271928628285726
0.3330642779668172
0.31778766711552936
0.3196888168652852
0.33523372809092206
0.31316863497098285
0.319853941599528
0.325138399998347
0.312237153450648
0.34133216738700867
0.3319360415140788
0.32246270775794983
0.3367210825284322
0.3347414235273997
0.3142566482226054
0.33008326093355816
0.3195533553759257
