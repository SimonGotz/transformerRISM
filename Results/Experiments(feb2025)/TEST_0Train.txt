CONFIGURATION: 
Training time: 277 
lr: 0.0002
wd: 0.005
d_model: 256
n_heads: 2
n_layers: 2
d_ff: 2048
batch_size: 2048
dropout: 0.2555918547347639
margin: 0.13336537888702704
epsilon: 1e-06
Train losses 
0.4930332973599434
0.48374606668949127
0.4433475434780121
0.39747411012649536
0.3327084556221962
0.3158138692378998
0.2907482013106346
0.2851746380329132
0.2838563844561577
0.2699098363518715
0.2665106952190399
0.26289910823106766
0.2654236629605293
0.25890712440013885
0.2649408280849457
Val losses 
0.3192883552827428
0.3186808075536463
0.25803713950513185
0.21478188057193107
0.17783962179685786
0.17407402291547794
0.16299753315316093
0.13791179566818723
0.1306203362234601
0.1267615313596947
0.1244511879952388
0.13121668839055353
0.12090973268644929
0.12616763257903063
0.12750551489351378
