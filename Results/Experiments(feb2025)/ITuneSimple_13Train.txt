CONFIGURATION: 
Learning rate: 4.06E-06 
margin: 0.98 
batch_size: 16 
number of layers: 1 
Train losses 
0.43487731107959043
0.43095960252814824
0.42428294795530813
0.4274104321444476
0.40959089475649374
0.41602669656276703
0.4034270387004923
0.38997787568304276
0.3952388675124557
0.40465196227585826
0.39310738024888214
0.39679688855453776
0.40259273604110435
0.3775142189529207
0.3840125521024068
0.3813038925329844
0.3800438164560883
0.3948577267152292
0.3904116815990872
0.3804437896719685
0.3792365231999644
0.3787726178213402
0.3739649774851622
0.36881867856891065
0.3855423416252489
0.5158991309227767
0.48685026985627633
0.4507211838607435
0.4147808272529531
0.3566474441024992
0.3271544778788531
0.30516462248784526
0.2821688505234542
0.25517397191789415
0.24293199446466235
0.2209977681990023
0.2151049945089552
0.21066485234984644
0.19045164463696657
0.18576051968115348
0.1839979682807569
0.18291765903985058
0.1738495268203594
0.16733315763650117
0.17012784900488676
0.1738462198663641
0.16344108934755677
0.1618244641356998
0.1624626006241198
0.16503308525791874
0.7836461351977454
0.7860877460903591
0.747736617481267
0.7233473504031146
0.7147124697764714
0.7008420021445663
0.6926499089709035
0.6716665022903019
0.6643270475996865
0.6505801899565591
0.6535906698968675
0.6285206961411017
0.6190919084681406
Val losses 
0.7241362457690032
0.6622948605081309
0.7049434786257537
0.6581907697345899
0.6483513365621152
0.6394047742304595
0.6482312959173452
0.6402801674345265
0.6231173847032629
0.5649028710697008
0.5839267367902009
0.5891998405041902
0.5898894087128017
