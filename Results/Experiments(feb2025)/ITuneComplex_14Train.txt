CONFIGURATION: 
lr: 2e-05
wd: 0.05
d_model: 16
n_heads: 16
n_layers: 1
d_ff: 256
batch_size: 128
dropout: 0.6615174215374081
margin: 0.5836501704381452
epsilon: 0.1
Train losses 
0.8198207376608208
0.8116853904368272
0.8222868771695379
0.8151441456666634
0.8125942972168994
0.8158682077678282
0.8041687803481942
0.8058804220228053
0.8033929938700661
0.8157643996067901
0.8039266289170108
0.7915776274097499
0.7909094762446275
0.8016939990556062
0.8111378772934871
0.8004929218719254
0.8166369653459805
0.8192732058354278
0.8016344691390422
0.8257564421909959
0.8139721306402292
0.8128162426735038
0.8106520318273288
0.8188564697308327
0.8017700999530394
Val losses 
0.3700254112482071
0.3670854036297117
0.36841041701180594
0.3689864192690168
0.365873851946422
0.3634036204644612
0.3712524473667145
0.3615761974028179
0.3686790487595967
0.3611590287515095
0.36575169009821756
0.3678673931530544
0.35849456063338686
0.3749287745782307
0.3835677738700594
0.3637245148420334
0.38049362174102236
0.35851690598896574
0.3612152487039566
0.35494575117315563
0.35423209198883604
0.3704310804605484
0.3674928694963455
0.3591801460300173
0.35003796219825745
