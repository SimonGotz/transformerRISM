CONFIGURATION: 
lr: 0.002
wd: 0.005
d_model: 16
n_heads: 8
n_layers: 3
d_ff: 2048
batch_size: 64
dropout: 0.5460166752913066
margin: 0.5862866345239218
epsilon: 1e-07
Train losses 
0.6913205994500055
0.6973264769271568
0.5698383084049932
0.6461852139896817
0.6455641234362567
0.6349279430177477
0.6206241093300007
0.6117656778406214
0.6014524888109278
0.5979818313210099
0.5963948625105399
0.5969899120154204
0.5912059428515257
0.5910090729042335
0.5891134350388139
0.5932003528983505
0.5884696635935042
0.588744173447291
0.5940565285859285
0.5828367297296171
0.5830595813415669
0.5900997749081365
0.5885481481198911
0.590680968761444
0.5856400205029382
Val losses 
0.5327511397855622
0.5648868296827588
0.5762342129434858
0.6364285541432244
0.668632156082562
0.5849348625966481
0.5850545998130526
0.5853852650948933
0.5850336232355663
0.5850460337741035
0.5850464893238885
0.5847879712070737
0.5847301759890148
0.5847116793904986
0.5845075377396175
0.5849313267639705
0.5849789104291371
0.584879572902407
0.5849895988191877
0.585462116769382
0.5849606075457164
0.5852496751717159
0.585047532405172
0.5849727136748177
0.5849234887531826
