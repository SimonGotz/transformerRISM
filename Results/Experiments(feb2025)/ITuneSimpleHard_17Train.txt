CONFIGURATION: 
lr: 1e-05
wd: 0.001
d_model: 256
n_heads: 8
n_layers: 3
d_ff: 128
batch_size: 128
dropout: 0.4006724176847419
margin: 0.23441417968927586
epsilon: 0.1
Train losses 
0.5482389553269343
0.5457610928300601
0.5380067313784984
0.5556672584654679
0.5357605032066801
0.6057590539775678
0.6279497836063157
0.6140696277369314
0.5909689962863922
0.6010205131858143
0.6010078356337192
0.6222797867967121
0.6145281471423248
0.6046894601921537
0.605570539164899
0.619409270695786
0.6027869524350807
Val losses 
0.29195002040692736
0.2852335763829095
0.2986430249043873
0.28383770265749525
0.2891836996589388
0.2979479559830257
0.2962630944592612
0.2962283662387303
0.3085400259920529
0.2989675902894565
0.31910692687545505
0.29117879058633533
0.3211561803306852
0.279124983719417
0.2959129192999431
0.29720896056720186
0.30015440178768976
