Run 0, config: lr: 1e-06 wd: 0.05 d_model: 128 n_heads: 2 n_layers: 1 d_ff: 128 batch_size: 2048 dropout: 0.5909746840349865 margin: 0.33885208878572654 epsilon: 1e-07 Train losses: 0.6654442548751831 0.6602848917245865 0.6537802219390869 0.6783205568790436 0.6566008776426315 0.6449735015630722 0.6578502953052521 0.653871163725853 0.6687323749065399 0.668344035744667 0.6563533395528793 0.6508679687976837 0.6766467839479446 0.6691505610942841 0.6516447961330414 0.6599190980195999 0.6799175292253494 0.6628986448049545 0.6431991159915924 0.6652660965919495 0.6768999248743057 0.6664209067821503 0.6561806350946426 0.6709676384925842 0.6443970501422882 Val losses: 0.3771030008792877 0.40448805689811707 0.3789665400981903 0.3726702332496643 0.3797275722026825 0.36576762795448303 0.3709758222103119 0.3620747923851013 0.4150981903076172 0.3516637682914734 0.3694872260093689 0.37178701162338257 0.4038485586643219 0.37592557072639465 0.3810502886772156 0.3766321539878845 0.37045562267303467 0.3837977647781372 0.375026136636734 0.3602428138256073 0.3961856961250305 0.35218900442123413 0.3714769184589386 0.37268006801605225 0.37286177277565 Testloss: 0.37509742627943743 
Run 1, config: lr: 1e-05 wd: 0.01 d_model: 128 n_heads: 8 n_layers: 2 d_ff: 128 batch_size: 2048 dropout: 0.02437554551251866 margin: 0.1206774983537393 epsilon: 1e-05 Train losses: 0.4300001263618469 0.4064370393753052 0.4092465788125992 0.40844952315092087 0.4169531539082527 0.4112495258450508 0.40003595501184464 0.40272393077611923 0.39950544387102127 0.4068503826856613 0.39276599138975143 0.3985655978322029 0.4043932780623436 0.39673593640327454 0.3833260238170624 0.394309937953949 0.3860347345471382 Val losses: 0.20326265692710876 0.18596281111240387 0.18883636593818665 0.16731105744838715 0.20390605926513672 0.19666343927383423 0.1706339567899704 0.20145545899868011 0.18209829926490784 0.1920536607503891 0.17629064619541168 0.1775912046432495 0.18430191278457642 0.17630450427532196 0.17959141731262207 0.1869295984506607 0.18723329901695251 Testloss: 0.19203528940581038 
Run 2, config: lr: 1e-05 wd: 0.05 d_model: 512 n_heads: 2 n_layers: 3 d_ff: 512 batch_size: 2048 dropout: 0.08548128089361536 margin: 0.5721939116003427 epsilon: 1e-05 Train losses: 0.9671632200479507 0.9380873441696167 0.9008874297142029 0.9138195067644119 0.8727934211492538 0.8710131794214249 0.8641689419746399 0.8667128682136536 0.8374106287956238 0.8081006854772568 0.824265792965889 0.7792066335678101 0.7820792347192764 0.7782974243164062 0.7769659608602524 0.7903184294700623 0.7601735293865204 0.7755225896835327 0.7506165355443954 0.7485683262348175 0.7259781509637833 0.7664067894220352 0.7558885961771011 0.7490985244512558 0.7653155624866486 Val losses: 0.5810601115226746 0.5630505084991455 0.5650283098220825 0.5814003348350525 0.47390317916870117 0.5357446670532227 0.5570333003997803 0.47436368465423584 0.4914345145225525 0.4876764118671417 0.49192023277282715 0.40129464864730835 0.4293079376220703 0.4224148392677307 0.44076454639434814 0.44316375255584717 0.4364519417285919 0.44223400950431824 0.42904871702194214 0.40597808361053467 0.4400734305381775 0.4521813988685608 0.40336930751800537 0.442062109708786 0.40842297673225403 Testloss: 0.39388719756560736 
Run 3, config: lr: 2e-06 wd: 0.005 d_model: 16 n_heads: 16 n_layers: 4 d_ff: 128 batch_size: 2048 dropout: 0.6215678427796328 margin: 0.40346299515682515 epsilon: 1e-06 Train losses: 0.6894350051879883 0.7190517038106918 0.7237315326929092 0.6686566323041916 0.671283483505249 0.6911046057939529 0.6878441721200943 0.6803179979324341 0.684366837143898 0.6831638216972351 0.6962459832429886 0.6781580299139023 0.6782992482185364 0.676890641450882 0.6750129610300064 0.6760232746601105 0.6823599636554718 0.689908042550087 0.6734300553798676 0.7029003649950027 0.6868767887353897 0.6836767792701721 0.6841709911823273 0.6641757637262344 0.6791628152132034 Val losses: 0.2993936538696289 0.3225618600845337 0.3059496283531189 0.31354665756225586 0.3030199408531189 0.30691730976104736 0.3080637753009796 0.34354168176651 0.3182346224784851 0.3072049915790558 0.3025238811969757 0.31599101424217224 0.31381291151046753 0.30466774106025696 0.3168877363204956 0.30602604150772095 0.2979657053947449 0.3188076317310333 0.31604352593421936 0.3170642554759979 0.3120594024658203 0.3199959099292755 0.3034116327762604 0.3188685476779938 0.29927578568458557 Testloss: 0.2966999426073541 
Run 4, config: lr: 0.001 wd: 0.0005 d_model: 256 n_heads: 8 n_layers: 2 d_ff: 256 batch_size: 2048 dropout: 0.0800339718079398 margin: 0.2934353830219245 epsilon: 0.01 Train losses: 0.5573771297931671 0.5390942692756653 0.5330507159233093 0.5336335301399231 0.514173686504364 0.5093746334314346 0.5026313066482544 0.4858167693018913 0.4502028524875641 0.453157015144825 0.43490178138017654 0.4207623824477196 0.44002778828144073 0.42858579754829407 0.421552874147892 0.40429622679948807 0.3947727754712105 0.40508176386356354 0.3934730216860771 0.401118665933609 0.41081552952528 0.40142151713371277 0.399743877351284 0.3880315274000168 0.38614024221897125 Val losses: 0.2277761846780777 0.24349439144134521 0.22289663553237915 0.2362602949142456 0.2169499397277832 0.23221518099308014 0.24368971586227417 0.23319414258003235 0.24445800483226776 0.24059349298477173 0.21456770598888397 0.20311161875724792 0.19458551704883575 0.21660107374191284 0.21101927757263184 0.20191428065299988 0.20120517909526825 0.18847453594207764 0.1927637755870819 0.19253169000148773 0.1936127096414566 0.18051853775978088 0.19117623567581177 0.18542784452438354 0.20180034637451172 Testloss: 0.1803368020225125 
Run 5, config: lr: 0.0001 wd: 0.05 d_model: 128 n_heads: 4 n_layers: 2 d_ff: 256 batch_size: 2048 dropout: 0.7680920815722478 margin: 0.5517895169843375 epsilon: 1e-06 Train losses: 0.7688235938549042 0.772195503115654 0.7562292218208313 0.7581208199262619 0.7794066965579987 0.7947497367858887 0.7832216024398804 0.7711368948221207 0.7751608937978745 0.7511766701936722 0.7507727891206741 0.7555321156978607 0.7485911101102829 0.7540241032838821 0.75292107462883 0.7793796062469482 0.7668636590242386 0.7522411942481995 0.7576271444559097 0.744327649474144 0.7671330571174622 0.7385759651660919 0.7616736590862274 0.7419313341379166 0.7549899518489838 Val losses: 0.29629793763160706 0.3017169237136841 0.3359626233577728 0.32186654210090637 0.3182174563407898 0.30824562907218933 0.3162330687046051 0.2717379033565521 0.30375486612319946 0.3317411541938782 0.3177642524242401 0.2914208769798279 0.31687718629837036 0.30062952637672424 0.30432575941085815 0.29825741052627563 0.29002779722213745 0.322111576795578 0.29983213543891907 0.33653631806373596 0.29916396737098694 0.2950402796268463 0.30916592478752136 0.2912052571773529 0.31112566590309143 Testloss: 0.35046991923253384 
Run 6, config: lr: 0.002 wd: 0.0005 d_model: 256 n_heads: 4 n_layers: 3 d_ff: 1024 batch_size: 2048 dropout: 0.5342455318479616 margin: 0.26962645987893935 epsilon: 0.001 Train losses: 0.5997304320335388 0.5918134450912476 0.5434645712375641 0.4740627482533455 0.4546652138233185 0.447096586227417 0.4504755139350891 0.4361783042550087 0.42484262585639954 0.41801348328590393 0.4180470257997513 0.4060515835881233 0.405579574406147 0.4138643592596054 0.40451501309871674 0.41048484295606613 0.40065719932317734 0.3995657190680504 0.39108777791261673 0.3984879106283188 0.38946282118558884 0.38994453102350235 0.38993368297815323 0.3853764161467552 0.38635168224573135 Val losses: 0.2402702122926712 0.2085856795310974 0.1630679965019226 0.1278969794511795 0.10184234380722046 0.11492409557104111 0.11289989203214645 0.11576861888170242 0.1162061095237732 0.12027586251497269 0.11536930501461029 0.11759635806083679 0.11294294893741608 0.11502741277217865 0.11289554834365845 0.11753816902637482 0.110881507396698 0.11505798995494843 0.11396387219429016 0.10493892431259155 0.11343744397163391 0.1086006760597229 0.10998517274856567 0.1092178076505661 0.11026522517204285 Testloss: 0.12489509186443286 
Run 7, config: lr: 0.001 wd: 0.005 d_model: 64 n_heads: 16 n_layers: 2 d_ff: 512 batch_size: 2048 dropout: 0.08242274296054629 margin: 0.6145387748765625 epsilon: 0.01 Train losses: 0.7487359493970871 0.7299120724201202 0.7353991717100143 0.7018036246299744 0.6919411420822144 0.6662205904722214 0.6443334817886353 0.6565993130207062 0.6423652172088623 0.6425997018814087 0.6399713009595871 0.6372952163219452 0.6228903383016586 0.6322806626558304 0.6317974478006363 0.6245603263378143 0.6147239208221436 0.6178973019123077 0.6183073818683624 Val losses: 0.34995561838150024 0.3524438440799713 0.33796119689941406 0.34318795800209045 0.31945180892944336 0.33107611536979675 0.3352668583393097 0.3239315450191498 0.3178761303424835 0.3356437385082245 0.34256085753440857 0.33523356914520264 0.34215596318244934 0.358515202999115 0.34399762749671936 0.34113019704818726 0.34306958317756653 0.35327157378196716 0.35357025265693665 Testloss: 0.30998676316535906 
Run 8, config: lr: 0.0002 wd: 0.001 d_model: 1024 n_heads: 16 n_layers: 3 d_ff: 128 batch_size: 1024 dropout: 0.41245117697295186 margin: 0.5196781513235245 epsilon: 0.1 Train losses: 0.7400797456502914 0.7615562379360199 0.7563637346029282 0.7428308874368668 0.7646099328994751 0.7779182717204094 0.7104762941598892 0.7817573472857475 0.7732372209429741 0.7593050673604012 0.7388556003570557 0.760201208293438 0.767182432115078 0.7973283231258392 0.755826361477375 0.7552939131855965 0.7594166621565819 0.7452872395515442 0.77679093927145 Val losses: 0.3992300033569336 0.41840529441833496 0.4069083333015442 0.4041275084018707 0.43654653429985046 0.437823086977005 0.40323570370674133 0.3952735662460327 0.4019854962825775 0.3927013874053955 0.4394676983356476 0.4115144908428192 0.4027724862098694 0.3814789056777954 0.4563986659049988 0.3734629154205322 0.39409351348876953 0.4402507245540619 0.4476889371871948 Testloss: 0.40005056411108414 
Run 9, config: lr: 0.0001 wd: 0.005 d_model: 64 n_heads: 8 n_layers: 2 d_ff: 2048 batch_size: 2048 dropout: 0.0802204170297543 margin: 0.32663754317361593 epsilon: 0.1 Train losses: 0.5769971311092377 0.5643588453531265 0.5726276934146881 0.5588782727718353 0.5516128689050674 0.5621278882026672 0.5419935137033463 0.553597629070282 0.5614901483058929 0.5541256368160248 0.55536849796772 0.544663280248642 0.5411005318164825 0.5259909778833389 0.550810843706131 0.5327296704053879 0.5492346733808517 0.5366907566785812 0.5382626056671143 0.5162254273891449 0.5425019711256027 0.5265637934207916 0.5423921793699265 0.5383014976978302 0.539446234703064 Val losses: 0.25428280234336853 0.23783054947853088 0.22720323503017426 0.23141899704933167 0.24335463345050812 0.2249048352241516 0.25631532073020935 0.2357179969549179 0.2472107857465744 0.2329138070344925 0.2390197217464447 0.24086560308933258 0.24051737785339355 0.24817657470703125 0.22852806746959686 0.2309848517179489 0.23338264226913452 0.2089918702840805 0.22778242826461792 0.2233716994524002 0.23930077254772186 0.2259235829114914 0.2241748571395874 0.23268651962280273 0.2290927618741989 Testloss: 0.2498456765869899 
Run 10, config: lr: 0.001 wd: 0.05 d_model: 1024 n_heads: 16 n_layers: 2 d_ff: 2048 batch_size: 1024 dropout: 0.1865127956905365 margin: 0.43601381067010553 epsilon: 1e-05 Train losses: 0.676497794687748 0.5774918347597122 0.5506066642701626 0.5370236858725548 0.5353503711521626 0.5685507208108902 0.5431502386927605 0.5342765189707279 0.5210758596658707 0.5028520822525024 0.4812547378242016 0.4839414991438389 0.4565817229449749 Val losses: 0.3698802888393402 0.2236451804637909 0.2054486870765686 0.26541826128959656 0.2484460324048996 0.2671782970428467 0.2810257077217102 0.3094483017921448 0.33337166905403137 0.29401081800460815 0.34735360741615295 0.3476012051105499 0.3737458288669586 Testloss: 0.23288142062856468 
Run 11, config: lr: 0.001 wd: 0.005 d_model: 512 n_heads: 4 n_layers: 1 d_ff: 256 batch_size: 2048 dropout: 0.3714352464014895 margin: 0.6172779765963078 epsilon: 0.1 Train losses: 0.8645504415035248 0.8541419059038162 0.8475974500179291 0.837881550192833 0.8488464057445526 0.839993491768837 0.8672018498182297 0.8494450896978378 0.8275257498025894 0.8492292612791061 0.8297550082206726 0.8216634094715118 0.8632528930902481 0.834633469581604 0.8330890834331512 0.8402921855449677 0.8448781669139862 Val losses: 0.48084214329719543 0.5107575058937073 0.5141910314559937 0.5067394375801086 0.5389617085456848 0.510635256767273 0.49994391202926636 0.530898928642273 0.49683040380477905 0.5005698800086975 0.501754879951477 0.47562819719314575 0.5108985304832458 0.47284239530563354 0.5193834900856018 0.5265483260154724 0.540913999080658 Testloss: 0.5487438355955415 
Run 12, config: lr: 2e-06 wd: 0.1 d_model: 128 n_heads: 2 n_layers: 4 d_ff: 256 batch_size: 2048 dropout: 0.7172788144802548 margin: 0.14795858904269688 epsilon: 1e-08 Train losses: 0.4993891343474388 0.5135078355669975 0.5171979367733002 0.5216327980160713 0.496593177318573 0.4945073500275612 0.5291823446750641 0.5233878344297409 0.5110906288027763 0.5006764903664589 0.5078816637396812 0.5053804814815521 0.5160070061683655 0.517794132232666 0.5006839260458946 0.5146165043115616 0.5063963383436203 0.5135359987616539 0.519203320145607 0.5080408006906509 0.5044679194688797 0.5056002363562584 0.5160470455884933 Val losses: 0.25956082344055176 0.25797238945961 0.2423027753829956 0.2422601282596588 0.25048327445983887 0.25665533542633057 0.26895278692245483 0.2642039954662323 0.27732276916503906 0.22403165698051453 0.2622435986995697 0.2824031114578247 0.25601449608802795 0.2492661327123642 0.2534242272377014 0.24557194113731384 0.2563496232032776 0.25114744901657104 0.2755216360092163 0.24690108001232147 0.26051992177963257 0.2632150650024414 0.2694413363933563 Testloss: 0.24861818645401043 
Run 13, config: lr: 1e-06 wd: 0.0001 d_model: 512 n_heads: 4 n_layers: 1 d_ff: 128 batch_size: 2048 dropout: 0.523287874976804 margin: 0.1023540660708702 epsilon: 1e-05 Train losses: 0.5373538732528687 0.5410953909158707 0.5257162153720856 0.5183657109737396 0.526266872882843 0.524044007062912 0.5354939848184586 0.5467629283666611 0.551831528544426 0.5144447609782219 0.5274888873100281 0.5448478758335114 0.5356418192386627 0.5498692095279694 0.5248803049325943 0.5204298943281174 0.5472733378410339 0.5245650410652161 0.5021215155720711 0.5285176932811737 0.5330679565668106 0.5289710760116577 0.5340156257152557 0.5290583223104477 0.5637716799974442 Val losses: 0.2706848084926605 0.2709466218948364 0.2835958003997803 0.3322356343269348 0.3116832673549652 0.32139575481414795 0.27900296449661255 0.28176379203796387 0.2810266315937042 0.3038212060928345 0.2974121570587158 0.3066371977329254 0.2972757816314697 0.28413379192352295 0.27858224511146545 0.2815130650997162 0.296372652053833 0.285579115152359 0.31187623739242554 0.2958434224128723 0.29534924030303955 0.2951492965221405 0.2881527841091156 0.2783866822719574 0.3098664879798889 Testloss: 0.3231414849535315 
Run 14, config: lr: 0.0001 wd: 0.05 d_model: 32 n_heads: 2 n_layers: 1 d_ff: 256 batch_size: 2048 dropout: 0.04860276631195362 margin: 0.9086778700940811 epsilon: 0.1 Train losses: 0.9943892061710358 0.9866264164447784 0.9825821071863174 1.0200181752443314 0.9895770102739334 0.9845632016658783 0.9865337759256363 0.9833941161632538 1.002200186252594 0.9973080009222031 0.9825548529624939 0.9956717193126678 0.985281229019165 0.9819842427968979 1.0062318742275238 1.007706105709076 0.9921638816595078 0.9886622875928879 0.9980527013540268 0.9756762534379959 1.0044006705284119 0.9719634056091309 0.9850035607814789 Val losses: 0.624289333820343 0.6072017550468445 0.6164418458938599 0.6147013306617737 0.6144149303436279 0.607530415058136 0.6091530919075012 0.6295890808105469 0.621939480304718 0.5943964719772339 0.6136306524276733 0.6386761665344238 0.6136752367019653 0.613369882106781 0.5883371829986572 0.606244683265686 0.6005744338035583 0.6044684052467346 0.5911158919334412 0.5882605910301208 0.5971035361289978 0.6269442439079285 0.6302118301391602 Testloss: 0.5985418036459331 
Run 15, config: lr: 1e-06 wd: 0.005 d_model: 1024 n_heads: 16 n_layers: 1 d_ff: 128 batch_size: 1024 dropout: 0.6367514906795301 margin: 0.46626199339757524 epsilon: 1e-05 Train losses: 0.7759419679641724 0.7807202264666557 0.7877349257469177 0.7553432509303093 0.7412542924284935 0.7499539703130722 0.7474131435155869 0.7792518585920334 0.7394974678754807 0.7032163441181183 0.75276068598032 0.7854339852929115 0.7585058733820915 0.7494689598679543 0.7828766033053398 0.766049787402153 0.760926827788353 0.7506323233246803 0.795833133161068 Val losses: 0.3526439964771271 0.33284130692481995 0.3693102300167084 0.35512852668762207 0.34252220392227173 0.3240559995174408 0.3673645853996277 0.3773481845855713 0.30534645915031433 0.37404173612594604 0.3284416198730469 0.3297901749610901 0.3765329122543335 0.329741895198822 0.3432771861553192 0.32475847005844116 0.3313559293746948 0.3583706021308899 0.3733542561531067 Testloss: 0.30481256632338594 
Run 16, config: lr: 2e-06 wd: 0.01 d_model: 64 n_heads: 8 n_layers: 4 d_ff: 1024 batch_size: 2048 dropout: 0.02837016356541744 margin: 0.15683225889224453 epsilon: 0.001 Train losses: 0.46449122577905655 0.43392252177000046 0.4411446899175644 0.44998128712177277 0.4448496252298355 0.4474131762981415 0.4595653787255287 0.4619615077972412 0.44936124235391617 0.4246979430317879 0.45383820682764053 0.44185271114110947 0.44786790758371353 0.435984306037426 0.43662069737911224 0.44144143909215927 0.4285677522420883 0.45398224145174026 0.4391543045639992 0.4335567504167557 0.424550399184227 0.4455742612481117 0.4150093346834183 0.4246736094355583 0.4184075817465782 Val losses: 0.17409439384937286 0.18229493498802185 0.17634649574756622 0.17635032534599304 0.17170417308807373 0.18092650175094604 0.1609247922897339 0.17048139870166779 0.17838221788406372 0.17204922437667847 0.1783006191253662 0.1754370629787445 0.18712231516838074 0.1679416447877884 0.15213102102279663 0.17084594070911407 0.17661111056804657 0.16751496493816376 0.17647460103034973 0.1893935352563858 0.18315653502941132 0.18295197188854218 0.15877337753772736 0.1620764434337616 0.1760159432888031 Testloss: 0.17988287649046467 
Run 17, config: lr: 1e-06 wd: 0.1 d_model: 32 n_heads: 16 n_layers: 4 d_ff: 512 batch_size: 2048 dropout: 0.41522629571462066 margin: 0.3827849079450455 epsilon: 0.001 Train losses: 0.682871088385582 0.6785582900047302 0.7065030634403229 0.6798898428678513 0.6857747733592987 0.6895694136619568 0.6690278500318527 0.6809321045875549 0.671001523733139 0.6686902344226837 0.695327490568161 0.6956993937492371 0.6688186079263687 0.65284663438797 0.6797475963830948 0.6879633218050003 0.6699158847332001 0.6534843891859055 0.6813042610883713 Val losses: 0.24968628585338593 0.25313901901245117 0.24340727925300598 0.26488620042800903 0.2592371106147766 0.25615063309669495 0.26301902532577515 0.27349230647087097 0.24281734228134155 0.27020829916000366 0.25887662172317505 0.27892163395881653 0.27164703607559204 0.24996651709079742 0.29120954871177673 0.24327786266803741 0.2569516897201538 0.26172858476638794 0.2670974135398865 Testloss: 0.25723360996514255 
Run 18, config: lr: 0.0002 wd: 0.005 d_model: 128 n_heads: 4 n_layers: 1 d_ff: 512 batch_size: 2048 dropout: 0.417172401340798 margin: 0.16499003017702712 epsilon: 0.001 Train losses: 0.5057269483804703 0.5235581174492836 0.544133648276329 0.5299849137663841 0.5012642666697502 0.5048793330788612 0.49489517509937286 0.5012744292616844 0.48641587048768997 0.48972392827272415 0.46996118128299713 0.48141732811927795 0.47110699117183685 0.4647996723651886 0.4814107269048691 0.4590085968375206 0.4522389695048332 0.4689619839191437 0.4729708805680275 0.46595121920108795 0.462404303252697 0.4511231854557991 0.45673250406980515 0.4711887091398239 0.45612338185310364 Val losses: 0.22668033838272095 0.21101978421211243 0.21936076879501343 0.21138595044612885 0.21965377032756805 0.201072096824646 0.19417504966259003 0.19702737033367157 0.19689787924289703 0.19048601388931274 0.18793384730815887 0.18566222488880157 0.1841367483139038 0.17539627850055695 0.19440019130706787 0.1982223093509674 0.183482825756073 0.17330750823020935 0.16162769496440887 0.17698663473129272 0.16605821251869202 0.1564134806394577 0.17924724519252777 0.15861426293849945 0.1849822700023651 Testloss: 0.1634845674271393 
Run 19, config: lr: 2e-05 wd: 0.0001 d_model: 32 n_heads: 8 n_layers: 3 d_ff: 512 batch_size: 2048 dropout: 0.023084526837338883 margin: 0.4547054300877501 epsilon: 1e-08 Train losses: 0.5943735241889954 0.6183914393186569 0.5939018577337265 0.5895213335752487 0.5965495705604553 0.5801550298929214 0.5694867223501205 0.5717197507619858 0.5539226233959198 0.5495281219482422 0.5601745694875717 0.5627161115407944 0.5543817281723022 0.5540520548820496 0.5592763423919678 0.5448983907699585 0.5502684563398361 0.5677845925092697 0.5372337847948074 0.535439133644104 0.5347550511360168 0.5505817830562592 0.537349209189415 0.5406704396009445 0.5325963497161865 Val losses: 0.35624492168426514 0.35263583064079285 0.3484993278980255 0.3638511896133423 0.3477470278739929 0.3409242331981659 0.35795333981513977 0.3478891849517822 0.3351862132549286 0.3321269452571869 0.3398681581020355 0.32009053230285645 0.3201434016227722 0.3293401896953583 0.33163440227508545 0.3373868465423584 0.31991681456565857 0.31934186816215515 0.30856987833976746 0.33254775404930115 0.3107708692550659 0.31690487265586853 0.3229673206806183 0.3131289780139923 0.31018975377082825 Testloss: 0.28513683943024587 
Run 20, config: lr: 2e-05 wd: 0.05 d_model: 512 n_heads: 8 n_layers: 2 d_ff: 128 batch_size: 2048 dropout: 0.3375652873215958 margin: 0.3582444546858553 epsilon: 1e-08 Train losses: 0.6622401773929596 0.6696006804704666 0.651228666305542 0.6622497588396072 0.6503192037343979 0.6756912469863892 0.6738698929548264 0.6735121011734009 0.6566934287548065 0.6548935025930405 0.6443440318107605 0.6647842824459076 0.65102519094944 0.6459428071975708 0.6623479127883911 0.6543988138437271 0.6455831229686737 0.6690271496772766 0.6283660531044006 0.6495800912380219 0.628792941570282 0.6539212465286255 0.6492438763380051 0.6402389109134674 0.6391148567199707 Val losses: 0.33364343643188477 0.3412221670150757 0.30243897438049316 0.3163033127784729 0.30888837575912476 0.323941707611084 0.3050028681755066 0.3108859956264496 0.30092954635620117 0.30693867802619934 0.2913825213909149 0.2731561064720154 0.3047875761985779 0.29589372873306274 0.2892289161682129 0.27412882447242737 0.29119354486465454 0.31154191493988037 0.3154612183570862 0.3136163353919983 0.31716716289520264 0.2848584055900574 0.31157463788986206 0.30436933040618896 0.26347580552101135 Testloss: 0.28434002302840616 
Run 21, config: lr: 0.001 wd: 0.0005 d_model: 16 n_heads: 2 n_layers: 2 d_ff: 256 batch_size: 2048 dropout: 0.48649740180474643 margin: 0.5054342814289793 epsilon: 0.001 Train losses: 0.751640185713768 0.7708286046981812 0.7375504970550537 0.6900327950716019 0.6522319465875626 0.6479880809783936 0.6209441423416138 0.6133177876472473 0.614920437335968 0.6027146130800247 0.6039554923772812 0.6031696051359177 0.5978630930185318 Val losses: 0.36562207341194153 0.3777743875980377 0.3647627532482147 0.331932008266449 0.35132238268852234 0.34632933139801025 0.3262796401977539 0.34480011463165283 0.3536091148853302 0.351688027381897 0.3557699918746948 0.3561072051525116 0.366360604763031 Testloss: 0.3521661507091543 
Run 22, config: lr: 0.001 wd: 0.005 d_model: 16 n_heads: 4 n_layers: 3 d_ff: 128 batch_size: 2048 dropout: 0.1094655540198799 margin: 0.7624116068770143 epsilon: 0.0001 Train losses: 0.8116779178380966 0.8004889041185379 0.7872863560914993 0.7730032056570053 0.7720074504613876 0.7712273597717285 0.7660436928272247 0.764154925942421 0.7563090622425079 Val losses: 0.4462131857872009 0.45261985063552856 0.4918045699596405 0.5013232827186584 0.5220310091972351 0.5558531284332275 0.5656830072402954 0.5847181081771851 0.5848231315612793 Testloss: 0.497949830990492 
Run 23, config: lr: 0.001 wd: 0.05 d_model: 16 n_heads: 8 n_layers: 1 d_ff: 2048 batch_size: 2048 dropout: 0.3239892501409687 margin: 0.7151849647678925 epsilon: 0.0001 Train losses: 0.8673575073480606 0.8281153589487076 0.778591126203537 0.777029424905777 0.7650275230407715 0.7739783674478531 0.7586937844753265 0.7580153346061707 0.7730347663164139 0.7628125995397568 0.766808807849884 0.7604915648698807 0.7725543677806854 0.7666033506393433 0.7582926601171494 0.7582636922597885 0.762923926115036 0.7563287764787674 0.7524406760931015 0.7577752321958542 0.7579120993614197 0.7618081122636795 0.7559179961681366 0.7585480362176895 0.7593676596879959 Val losses: 0.4788391590118408 0.47317492961883545 0.4838372468948364 0.5119493007659912 0.554785966873169 0.5551716089248657 0.5655482411384583 0.5643157958984375 0.5597848296165466 0.5589335560798645 0.5627269744873047 0.577818751335144 0.5668683648109436 0.5699731111526489 0.5595837831497192 0.5644361972808838 0.564111590385437 0.568073034286499 0.5741982460021973 0.5602365732192993 0.5746489763259888 0.5595363974571228 0.5708927512168884 0.5634609460830688 0.5702216029167175 Testloss: 0.5018719850618217 
Run 24, config: lr: 0.0001 wd: 0.01 d_model: 512 n_heads: 16 n_layers: 1 d_ff: 256 batch_size: 2048 dropout: 0.7567930524846722 margin: 0.5034157895054295 epsilon: 1e-05 Train losses: 0.7468083649873734 0.7630553841590881 0.7535637617111206 0.7581380307674408 0.761975422501564 0.7486063838005066 0.7387131303548813 0.7471629530191422 0.749676451086998 0.7538929134607315 0.7574194967746735 0.7624522298574448 0.7635819166898727 0.7453414499759674 0.7593645006418228 0.7500420659780502 0.7617885321378708 0.7618056684732437 0.7422774881124496 Val losses: 0.34006163477897644 0.36261841654777527 0.35760971903800964 0.38572943210601807 0.3659381866455078 0.3652312457561493 0.3673744201660156 0.3406408429145813 0.3701464831829071 0.3734809458255768 0.36367806792259216 0.34225529432296753 0.3312776982784271 0.3731139302253723 0.34372714161872864 0.3321024477481842 0.348037451505661 0.3534759283065796 0.3605775535106659 Testloss: 0.31893643297291263 
